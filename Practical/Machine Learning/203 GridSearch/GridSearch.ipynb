{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 11:46:56.583097: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 11:47:00.619671: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-23 11:47:00.619710: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-23 11:47:00.998097: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-23 11:47:05.733614: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-23 11:47:05.733835: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-23 11:47:05.733849: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"num_pregnant\",\n",
    "    \"glucose_concentration\",\n",
    "    \"blood_pressure\",\n",
    "    \"skin_thickness\",\n",
    "    \"serum_insulin\",\n",
    "    \"BMI\",\n",
    "    \"pedigree_function\",\n",
    "    \"age\",\n",
    "    \"class\",\n",
    "]\n",
    "\n",
    "data_path = \"https://raw.githubusercontent.com/mkhalid1/Machine-Learning-Projects-Python-/master/Grid%20Search/pima-indians-diabetes.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_pregnant</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>serum_insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>version https://git-lfs.github.com/spec/v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oid sha256:9730471d92c4325d45472d7088bbcb30197...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>size 23628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        num_pregnant  glucose_concentration  \\\n",
       "0         version https://git-lfs.github.com/spec/v1                    NaN   \n",
       "1  oid sha256:9730471d92c4325d45472d7088bbcb30197...                    NaN   \n",
       "2                                         size 23628                    NaN   \n",
       "\n",
       "   blood_pressure  skin_thickness  serum_insulin  BMI  pedigree_function  age  \\\n",
       "0             NaN             NaN            NaN  NaN                NaN  NaN   \n",
       "1             NaN             NaN            NaN  NaN                NaN  NaN   \n",
       "2             NaN             NaN            NaN  NaN                NaN  NaN   \n",
       "\n",
       "   class  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove first 9 non-data rows\n",
    "df = df.iloc[9:]\n",
    "\n",
    "# Replace NaN (Not a Number) values with 0 in each column\n",
    "for col in columns:\n",
    "    df[col].replace(0, np.NaN, inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)  # Drop all rows with missing values\n",
    "dataset = df.values  # Convert dataframe to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 8)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Normalize the data using sklearn StandardScaler\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m StandardScaler\n\u001b[0;32m----> 7\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\u001b[39m.\u001b[39;49mfit(X)\n\u001b[1;32m      9\u001b[0m \u001b[39m# Transform and display the training data\u001b[39;00m\n\u001b[1;32m     10\u001b[0m X_standardized \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/python/3.10.4/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:809\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 809\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[0;32m/opt/python/3.10.4/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:844\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[39m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \n\u001b[1;32m    814\u001b[0m \u001b[39mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[39m    Fitted scaler.\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    843\u001b[0m first_call \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 844\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    845\u001b[0m     X,\n\u001b[1;32m    846\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    847\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[1;32m    848\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    849\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_call,\n\u001b[1;32m    850\u001b[0m )\n\u001b[1;32m    851\u001b[0m n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m    853\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/python/3.10.4/lib/python3.10/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m/opt/python/3.10.4/lib/python3.10/site-packages/sklearn/utils/validation.py:909\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[1;32m    908\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[0;32m--> 909\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    910\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    912\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    915\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    916\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 8)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:, 8].astype(int)\n",
    "\n",
    "# Normalize the data using sklearn StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "\n",
    "# Transform and display the training data\n",
    "X_standardized = scaler.transform(X)\n",
    "\n",
    "data = pd.DataFrame(X_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learn_rate, dropout_rate):\n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=8, kernel_initializer=\"normal\", activation=\"relu\"))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, input_dim=8, kernel_initializer=\"normal\", activation=\"relu\"))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the model\n",
    "    adam = Adam(lr=learn_rate)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model without Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/1\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "130/130 [==============================] - 2s 18ms/step - loss: 0.6829 - acc: 0.9538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x296c6eed388>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare parameter values\n",
    "dropout_rate = 0.1\n",
    "epochs = 1\n",
    "batch_size = 20\n",
    "learn_rate = 0.001\n",
    "\n",
    "# Create the model object by calling the create_model function we created above\n",
    "model = create_model(learn_rate, dropout_rate)\n",
    "\n",
    "# Fit the model onto the training data\n",
    "model.fit(X_standardized, Y, batch_size=batch_size, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Hyper-parameters using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learn_rate, dropout_rate):\n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=8, kernel_initializer=\"normal\", activation=\"relu\"))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, input_dim=8, kernel_initializer=\"normal\", activation=\"relu\"))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the model\n",
    "    adam = Adam(lr=learn_rate)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create the model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 1s 5ms/step - loss: 0.6921 - acc: 0.5865\n",
      "26/26 [==============================] - 0s 5ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=0.962, total=   1.6s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "104/104 [==============================] - 1s 6ms/step - loss: 0.6933 - acc: 0.6250\n",
      "26/26 [==============================] - 0s 5ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=1.000, total=   1.9s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 0.6909 - acc: 0.7308\n",
      "26/26 [==============================] - 0s 6ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=1.000, total=   2.0s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "104/104 [==============================] - 1s 6ms/step - loss: 0.6948 - acc: 0.5865\n",
      "26/26 [==============================] - 0s 11ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=0.923, total=   1.8s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    7.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 0.6869 - acc: 0.9038\n",
      "26/26 [==============================] - 0s 8ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=1.000, total=   1.9s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 0.4959 - acc: 0.9615\n",
      "26/26 [==============================] - 0s 8ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=1.000, total=   2.3s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   11.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "104/104 [==============================] - 1s 8ms/step - loss: 0.6483 - acc: 0.9135\n",
      "26/26 [==============================] - 0s 9ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=1.000, total=   1.9s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   13.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 0.5174 - acc: 1.0000\n",
      "26/26 [==============================] - 0s 12ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=1.000, total=   2.0s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   15.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "104/104 [==============================] - 1s 9ms/step - loss: 0.4405 - acc: 0.9904\n",
      "26/26 [==============================] - 0s 16ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=1.000, total=   2.0s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   17.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 0.5665 - acc: 0.9615\n",
      "26/26 [==============================] - 0s 14ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=1.000, total=   2.2s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 1s 10ms/step - loss: 0.0932 - acc: 0.9615\n",
      "26/26 [==============================] - 0s 14ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.2, score=1.000, total=   2.5s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 1s 11ms/step - loss: 0.1186 - acc: 0.9231\n",
      "26/26 [==============================] - 0s 14ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.2, score=1.000, total=   2.2s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 1s 11ms/step - loss: 0.1233 - acc: 0.9327\n",
      "26/26 [==============================] - 0s 15ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.2, score=1.000, total=   2.3s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 1s 12ms/step - loss: 0.0961 - acc: 0.9808\n",
      "26/26 [==============================] - 0s 16ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.2, score=1.000, total=   2.4s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 1s 12ms/step - loss: 0.1119 - acc: 0.9423\n",
      "26/26 [==============================] - 0s 17ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=1, learn_rate=0.2, score=1.000, total=   2.5s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 1s 13ms/step - loss: 0.6859 - acc: 0.9808\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 273us/step - loss: 0.6741 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 431us/step - loss: 0.6582 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 259us/step - loss: 0.6384 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 299us/step - loss: 0.6156 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 20ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.001, score=1.000, total=   2.8s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 1s 14ms/step - loss: 0.6903 - acc: 0.7115\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 304us/step - loss: 0.6751 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 309us/step - loss: 0.6572 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 357us/step - loss: 0.6369 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 328us/step - loss: 0.6146 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 22ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.001, score=1.000, total=   2.8s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 2s 15ms/step - loss: 0.6813 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 304us/step - loss: 0.6603 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 349us/step - loss: 0.6333 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 290us/step - loss: 0.6009 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 290us/step - loss: 0.5648 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 20ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.001, score=1.000, total=   2.9s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 0.6893 - acc: 0.7308\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 146us/step - loss: 0.6720 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 298us/step - loss: 0.6536 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 290us/step - loss: 0.6342 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 261us/step - loss: 0.6132 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 21ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.001, score=1.000, total=   3.0s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 2s 21ms/step - loss: 0.6878 - acc: 0.8462\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 384us/step - loss: 0.6728 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 348us/step - loss: 0.6571 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 357us/step - loss: 0.6408 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 371us/step - loss: 0.6237 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 30ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.001, score=1.000, total=   3.9s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 2s 20ms/step - loss: 0.5671 - acc: 0.9712\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 334us/step - loss: 0.2071 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 347us/step - loss: 0.0226 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 288us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 529us/step - loss: 6.6346e-04 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 31ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.02, score=1.000, total=   3.8s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 3s 27ms/step - loss: 0.4565 - acc: 0.9808\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 310us/step - loss: 0.0374 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 379us/step - loss: 6.8638e-04 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 348us/step - loss: 7.9544e-05 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 444us/step - loss: 3.8229e-05 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 30ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.02, score=1.000, total=   4.8s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 2s 21ms/step - loss: 0.6062 - acc: 0.9231\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 467us/step - loss: 0.2927 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 481us/step - loss: 0.0468 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 423us/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 480us/step - loss: 0.0010 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 31ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.02, score=1.000, total=   4.2s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 2s 23ms/step - loss: 0.4379 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 593us/step - loss: 0.0416 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 386us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 357us/step - loss: 9.7920e-05 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 376us/step - loss: 4.3776e-05 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 32ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.02, score=1.000, total=   4.2s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 2s 21ms/step - loss: 0.4972 - acc: 0.9808\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 412us/step - loss: 0.0722 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 380us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 300us/step - loss: 2.9932e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 320us/step - loss: 1.2360e-04 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 26ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.02, score=1.000, total=   4.0s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 2s 20ms/step - loss: 0.1542 - acc: 0.9135\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 454us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 340us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 328us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 336us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 33ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.2, score=1.000, total=   3.8s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 2s 21ms/step - loss: 0.1326 - acc: 0.9519\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 478us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 256us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 377us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 319us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 30ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.2, score=1.000, total=   4.0s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 2s 22ms/step - loss: 0.1310 - acc: 0.9423\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 473us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 500us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 357us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 338us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 31ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.2, score=1.000, total=   4.0s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 2s 22ms/step - loss: 0.0902 - acc: 0.9904\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 445us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 396us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 308us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 347us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 36ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.2, score=1.000, total=   4.1s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 2s 23ms/step - loss: 0.1252 - acc: 0.9135\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 448us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 319us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 329us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 338us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 32ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=5, learn_rate=0.2, score=1.000, total=   4.1s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 2s 23ms/step - loss: 0.6877 - acc: 0.8365\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 452us/step - loss: 0.6690 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 328us/step - loss: 0.6489 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 319us/step - loss: 0.6271 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 357us/step - loss: 0.6029 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 338us/step - loss: 0.5750 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 308us/step - loss: 0.5439 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 346us/step - loss: 0.5098 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 369us/step - loss: 0.4724 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 445us/step - loss: 0.4337 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 34ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.001, score=1.000, total=   4.4s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 3s 25ms/step - loss: 0.6945 - acc: 0.4231\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 502us/step - loss: 0.6836 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 330us/step - loss: 0.6748 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 164us/step - loss: 0.6662 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 367us/step - loss: 0.6571 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 328us/step - loss: 0.6474 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 386us/step - loss: 0.6367 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 369us/step - loss: 0.6249 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 376us/step - loss: 0.6114 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 367us/step - loss: 0.5962 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 34ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.001, score=1.000, total=   4.6s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 3s 26ms/step - loss: 0.6829 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 405us/step - loss: 0.6662 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 615us/step - loss: 0.6473 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 347us/step - loss: 0.6265 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 626us/step - loss: 0.6032 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 418us/step - loss: 0.5769 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 357us/step - loss: 0.5474 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 396us/step - loss: 0.5150 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 376us/step - loss: 0.4796 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 385us/step - loss: 0.4415 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 37ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.001, score=1.000, total=   4.7s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 3s 26ms/step - loss: 0.6900 - acc: 0.8942\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 658us/step - loss: 0.6817 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 488us/step - loss: 0.6730 - acc: 1.0000\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 541us/step - loss: 0.6639 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 513us/step - loss: 0.6540 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 463us/step - loss: 0.6433 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 533us/step - loss: 0.6314 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 396us/step - loss: 0.6181 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 434us/step - loss: 0.6031 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 427us/step - loss: 0.5863 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 36ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.001, score=1.000, total=   4.8s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 3s 28ms/step - loss: 0.6840 - acc: 0.9904\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 372us/step - loss: 0.6672 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 483us/step - loss: 0.6475 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 462us/step - loss: 0.6249 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 322us/step - loss: 0.5990 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 521us/step - loss: 0.5687 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 435us/step - loss: 0.5342 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 478us/step - loss: 0.4961 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 446us/step - loss: 0.4548 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 559us/step - loss: 0.4118 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 50ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.001, score=1.000, total=   5.3s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 3s 33ms/step - loss: 0.4634 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 477us/step - loss: 0.0676 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 386us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 386us/step - loss: 1.3278e-04 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 396us/step - loss: 4.5339e-05 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 396us/step - loss: 3.1415e-05 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 387us/step - loss: 2.7243e-05 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 394us/step - loss: 2.5509e-05 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 426us/step - loss: 2.4659e-05 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 405us/step - loss: 2.4001e-05 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 47ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=1.000, total=   5.9s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.5053 - acc: 0.9519\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 504us/step - loss: 0.0862 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 240us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 424us/step - loss: 4.6112e-04 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 453us/step - loss: 1.5646e-04 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 444us/step - loss: 1.1183e-04 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 286us/step - loss: 9.3802e-05 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 426us/step - loss: 8.6482e-05 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 424us/step - loss: 8.1421e-05 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 415us/step - loss: 7.7615e-05 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 53ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=1.000, total=   6.0s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.5312 - acc: 0.9615\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 467us/step - loss: 0.1151 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 407us/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 387us/step - loss: 4.7569e-04 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 397us/step - loss: 1.5567e-04 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 349us/step - loss: 1.0334e-04 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 396us/step - loss: 8.5968e-05 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 377us/step - loss: 7.9066e-05 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 397us/step - loss: 7.4521e-05 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 357us/step - loss: 7.1092e-05 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 42ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=1.000, total=   5.7s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 3s 30ms/step - loss: 0.5416 - acc: 0.9904\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 444us/step - loss: 0.1068 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 444us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 367us/step - loss: 1.8210e-04 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 377us/step - loss: 4.8844e-05 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 427us/step - loss: 3.1542e-05 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - ETA: 0s - loss: 1.5659e-05 - acc: 1.000 - 0s 367us/step - loss: 2.6834e-05 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 354us/step - loss: 2.5089e-05 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 388us/step - loss: 2.4118e-05 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 376us/step - loss: 2.3466e-05 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 44ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=1.000, total=   5.4s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.5009 - acc: 0.9904\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 458us/step - loss: 0.0865 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 386us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 386us/step - loss: 3.9678e-04 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 296us/step - loss: 1.3691e-04 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 490us/step - loss: 9.2149e-05 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 346us/step - loss: 7.8173e-05 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 405us/step - loss: 7.0899e-05 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 358us/step - loss: 6.7146e-05 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 426us/step - loss: 6.4003e-05 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 49ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=1.000, total=   5.6s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1220 - acc: 0.9231\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 550us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 376us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 396us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 448us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 472us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 473us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 473us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 509us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 455us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 47ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=1.000, total=   5.6s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 3s 34ms/step - loss: 0.1090 - acc: 0.9519\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 548us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 396us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 405us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 375us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 367us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 335us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 375us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 376us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 386us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 45ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=1.000, total=   5.7s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.0767 - acc: 0.9904\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 473us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 368us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 442us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 360us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 405us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 350us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 415us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 377us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 386us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 50ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=1.000, total=   5.8s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 4s 36ms/step - loss: 0.0882 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 540us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 375us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 386us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 365us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 428us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 395us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 423us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 443us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 397us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 48ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=1.000, total=   6.1s\n",
      "[CV] batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 3s 34ms/step - loss: 0.1387 - acc: 0.9519\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 557us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 386us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 407us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 355us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 426us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 461us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 415us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 453us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 397us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 1s 57ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=1.000, total=   6.2s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 4s 43ms/step - loss: 0.6941 - acc: 0.5769\n",
      "26/26 [==============================] - 2s 70ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=0.962, total=   7.5s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 5s 44ms/step - loss: 0.6805 - acc: 1.0000\n",
      "26/26 [==============================] - 2s 68ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=1.000, total=   7.4s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 4s 37ms/step - loss: 0.6916 - acc: 0.7308\n",
      "26/26 [==============================] - 2s 59ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=1.000, total=   6.3s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 4s 39ms/step - loss: 0.6738 - acc: 0.9712\n",
      "26/26 [==============================] - 1s 56ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=1.000, total=   6.3s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 4s 39ms/step - loss: 0.6823 - acc: 0.9904\n",
      "26/26 [==============================] - 2s 60ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=1.000, total=   6.5s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 4s 41ms/step - loss: 0.5353 - acc: 0.9808\n",
      "26/26 [==============================] - 2s 62ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=1.000, total=   6.7s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 4s 41ms/step - loss: 0.5566 - acc: 0.9327\n",
      "26/26 [==============================] - 2s 61ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=1.000, total=   6.7s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "104/104 [==============================] - 4s 43ms/step - loss: 0.5749 - acc: 0.9327\n",
      "26/26 [==============================] - 2s 60ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=1.000, total=   6.9s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 5s 44ms/step - loss: 0.5598 - acc: 0.9712\n",
      "26/26 [==============================] - 2s 77ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=1.000, total=   7.5s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 5s 51ms/step - loss: 0.4563 - acc: 0.9904\n",
      "26/26 [==============================] - 2s 79ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=1.000, total=   8.5s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 5s 50ms/step - loss: 0.3960 - acc: 0.9135\n",
      "26/26 [==============================] - 2s 69ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=1.000, total=   7.9s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 5s 46ms/step - loss: 0.1212 - acc: 0.9519\n",
      "26/26 [==============================] - 2s 68ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=1.000, total=   7.4s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 5s 47ms/step - loss: 0.1719 - acc: 0.9423\n",
      "26/26 [==============================] - 2s 68ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=1.000, total=   7.5s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 5s 48ms/step - loss: 0.1656 - acc: 0.9231\n",
      "26/26 [==============================] - 2s 73ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=1.000, total=   7.8s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 5s 49ms/step - loss: 0.1160 - acc: 0.9712\n",
      "26/26 [==============================] - 2s 75ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=1.000, total=   7.8s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 5s 51ms/step - loss: 0.6942 - acc: 0.5481\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 500us/step - loss: 0.6834 - acc: 0.9712\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 453us/step - loss: 0.6744 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 540us/step - loss: 0.6652 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 550us/step - loss: 0.6553 - acc: 1.0000\n",
      "26/26 [==============================] - 2s 76ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=1.000, total=   8.3s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 6s 57ms/step - loss: 0.6909 - acc: 0.7596\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 774us/step - loss: 0.6806 - acc: 0.9904\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 543us/step - loss: 0.6703 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 540us/step - loss: 0.6608 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 648us/step - loss: 0.6492 - acc: 1.0000\n",
      "26/26 [==============================] - 2s 92ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=1.000, total=   9.5s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 6s 61ms/step - loss: 0.6820 - acc: 0.9519\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 640us/step - loss: 0.6634 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 623us/step - loss: 0.6450 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 592us/step - loss: 0.6279 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 540us/step - loss: 0.5987 - acc: 1.0000\n",
      "26/26 [==============================] - 2s 87ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=1.000, total=   9.9s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 5s 53ms/step - loss: 0.6913 - acc: 0.7404\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 615us/step - loss: 0.6817 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 493us/step - loss: 0.6707 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 494us/step - loss: 0.6610 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 502us/step - loss: 0.6482 - acc: 1.0000\n",
      "26/26 [==============================] - 2s 82ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=1.000, total=   8.7s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 6s 55ms/step - loss: 0.6900 - acc: 0.7019\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 630us/step - loss: 0.6728 - acc: 0.9904\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 511us/step - loss: 0.6553 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 500us/step - loss: 0.6356 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 501us/step - loss: 0.6185 - acc: 1.0000\n",
      "26/26 [==============================] - 2s 81ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=1.000, total=   8.9s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 6s 55ms/step - loss: 0.5613 - acc: 0.9712\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 698us/step - loss: 0.1720 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 549us/step - loss: 0.0541 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 722us/step - loss: 0.0155 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 704us/step - loss: 0.0215 - acc: 1.0000\n",
      "26/26 [==============================] - 2s 84ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=1.000, total=   9.3s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 6s 56ms/step - loss: 0.4946 - acc: 0.9519\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 624us/step - loss: 0.0958 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 481us/step - loss: 0.0248 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 559us/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 538us/step - loss: 7.0557e-04 - acc: 1.0000\n",
      "26/26 [==============================] - 2s 86ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=1.000, total=   9.2s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 6s 57ms/step - loss: 0.5825 - acc: 0.9712\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 647us/step - loss: 0.2418 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 684us/step - loss: 0.0422 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 789us/step - loss: 0.0189 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 702us/step - loss: 0.0125 - acc: 1.0000\n",
      "26/26 [==============================] - 3s 107ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=1.000, total=   9.9s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 8s 73ms/step - loss: 0.5306 - acc: 0.9519\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 769us/step - loss: 0.1524 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 672us/step - loss: 0.0273 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 577us/step - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 568us/step - loss: 0.0254 - acc: 1.0000\n",
      "26/26 [==============================] - 3s 106ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=1.000, total=  11.7s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 6s 60ms/step - loss: 0.6075 - acc: 0.9519\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 662us/step - loss: 0.2953 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 471us/step - loss: 0.1647 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 485us/step - loss: 0.0820 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 542us/step - loss: 0.0913 - acc: 1.0000\n",
      "26/26 [==============================] - 2s 90ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=1.000, total=   9.8s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 6s 60ms/step - loss: 0.0995 - acc: 0.9904\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 540us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 507us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 559us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 541us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 2s 91ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=1.000, total=   9.8s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 6s 60ms/step - loss: 0.1388 - acc: 0.9231\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 656us/step - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 512us/step - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 521us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 599us/step - loss: 3.0823e-06 - acc: 1.0000\n",
      "26/26 [==============================] - 2s 94ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=1.000, total=   9.9s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 7s 64ms/step - loss: 0.0845 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 791us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 719us/step - loss: 1.2216e-07 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 589us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 631us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 2s 95ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=1.000, total=  10.3s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 7s 67ms/step - loss: 0.1123 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 712us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 647us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 638us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 611us/step - loss: 1.2999e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 3s 113ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=1.000, total=  11.0s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 8s 81ms/step - loss: 0.1196 - acc: 0.9327\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 770us/step - loss: 0.0125 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 677us/step - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 654us/step - loss: 9.4794e-04 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 504us/step - loss: 0.0053 - acc: 1.0000\n",
      "26/26 [==============================] - 3s 102ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=1.000, total=  12.5s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 7s 68ms/step - loss: 0.6878 - acc: 0.7692\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 575us/step - loss: 0.6648 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 597us/step - loss: 0.6433 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 474us/step - loss: 0.6173 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 601us/step - loss: 0.5975 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 523us/step - loss: 0.5748 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 542us/step - loss: 0.5389 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 515us/step - loss: 0.5133 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 538us/step - loss: 0.4865 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 549us/step - loss: 0.4498 - acc: 1.0000\n",
      "26/26 [==============================] - 3s 101ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=1.000, total=  11.2s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 7s 68ms/step - loss: 0.6947 - acc: 0.6346\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 669us/step - loss: 0.6866 - acc: 0.9519\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 549us/step - loss: 0.6802 - acc: 0.9904\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 628us/step - loss: 0.6746 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 610us/step - loss: 0.6693 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 676us/step - loss: 0.6640 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 701us/step - loss: 0.6587 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 817us/step - loss: 0.6535 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 740us/step - loss: 0.6483 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 817us/step - loss: 0.6432 - acc: 1.0000\n",
      "26/26 [==============================] - 3s 109ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=1.000, total=  11.4s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 8s 78ms/step - loss: 0.6888 - acc: 0.8750\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 644us/step - loss: 0.6734 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 831us/step - loss: 0.6553 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 806us/step - loss: 0.6378 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 884us/step - loss: 0.6155 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 866us/step - loss: 0.5970 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 847us/step - loss: 0.5676 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 895us/step - loss: 0.5373 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 866us/step - loss: 0.5082 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 850us/step - loss: 0.4764 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 3s 123ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=1.000, total=  13.0s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 8s 76ms/step - loss: 0.6833 - acc: 0.8942\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 781us/step - loss: 0.6606 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 907us/step - loss: 0.6416 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 902us/step - loss: 0.6144 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 879us/step - loss: 0.6016 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 908us/step - loss: 0.5725 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 761us/step - loss: 0.5320 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 992us/step - loss: 0.4993 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 685us/step - loss: 0.4672 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 646us/step - loss: 0.4446 - acc: 1.0000\n",
      "26/26 [==============================] - 3s 129ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=1.000, total=  12.9s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 9s 87ms/step - loss: 0.6838 - acc: 0.9808\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 686us/step - loss: 0.6634 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 552us/step - loss: 0.6398 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 570us/step - loss: 0.6107 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 539us/step - loss: 0.5892 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 549us/step - loss: 0.5468 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 639us/step - loss: 0.5178 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 638us/step - loss: 0.5004 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 637us/step - loss: 0.4578 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 638us/step - loss: 0.4248 - acc: 1.0000\n",
      "26/26 [==============================] - 3s 115ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=1.000, total=  13.7s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 8s 74ms/step - loss: 0.4965 - acc: 0.9615\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 734us/step - loss: 0.1222 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 943us/step - loss: 0.0198 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 836us/step - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 893us/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 991us/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 806us/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 819us/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 938us/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0050 - acc: 1.0000\n",
      "26/26 [==============================] - 4s 140ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=1.000, total=  13.0s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 8s 76ms/step - loss: 0.5126 - acc: 0.9231\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 654us/step - loss: 0.1245 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 533us/step - loss: 0.0358 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 663us/step - loss: 0.0207 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 648us/step - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 708us/step - loss: 0.0281 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 662us/step - loss: 0.0205 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 667us/step - loss: 0.0221 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 676us/step - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 693us/step - loss: 0.0140 - acc: 1.0000\n",
      "26/26 [==============================] - 3s 116ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=1.000, total=  12.5s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 8s 77ms/step - loss: 0.6367 - acc: 0.9038\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 686us/step - loss: 0.3996 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 623us/step - loss: 0.1816 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 703us/step - loss: 0.1085 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 652us/step - loss: 0.0799 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 747us/step - loss: 0.0879 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 716us/step - loss: 0.0800 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 533us/step - loss: 0.1074 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 731us/step - loss: 0.0613 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 474us/step - loss: 0.0522 - acc: 1.0000\n",
      "26/26 [==============================] - 3s 119ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=1.000, total=  12.7s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 9s 89ms/step - loss: 0.4474 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 887us/step - loss: 0.0579 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 880us/step - loss: 0.0110 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 932us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0068 - acc: 1.0000    - 0s 819us/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 840us/step - loss: 3.9398e-04 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 851us/step - loss: 5.7435e-04 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - ETA: 0s - loss: 8.5374e-05 - acc: 1.000 - 0s 866us/step - loss: 8.3549e-05 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 831us/step - loss: 7.8406e-04 - acc: 1.0000\n",
      "26/26 [==============================] - 4s 143ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=1.000, total=  14.8s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 8s 81ms/step - loss: 0.5275 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 626us/step - loss: 0.1203 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 672us/step - loss: 0.0211 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 662us/step - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 800us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 673us/step - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 695us/step - loss: 4.6810e-04 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 790us/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 782us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 796us/step - loss: 0.0011 - acc: 1.0000\n",
      "26/26 [==============================] - 3s 121ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=1.000, total=  13.4s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.2 ......\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 8s 81ms/step - loss: 0.1385 - acc: 0.9808\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 707us/step - loss: 1.1824e-07 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 597us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 573us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 640us/step - loss: 1.4599e-07 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 716us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 676us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 655us/step - loss: 1.0372e-07 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 705us/step - loss: 1.0219e-07 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 689us/step - loss: 0.0011 - acc: 1.0000\n",
      "26/26 [==============================] - 3s 123ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.2, score=1.000, total=  13.0s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.2 ......\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 8s 80ms/step - loss: 0.2819 - acc: 0.9423\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 840us/step - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 689us/step - loss: 0.0152 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 566us/step - loss: 0.0097 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 743us/step - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 667us/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 695us/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 658us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 677us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 630us/step - loss: 0.0046 - acc: 1.0000\n",
      "26/26 [==============================] - 3s 134ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.2, score=1.000, total=  13.5s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.2 ......\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 10s 92ms/step - loss: 0.0995 - acc: 0.9904\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 673us/step - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 760us/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 895us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 671us/step - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 956us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 820us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 853us/step - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 780us/step - loss: 6.5955e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 692us/step - loss: 0.0035 - acc: 1.0000\n",
      "26/26 [==============================] - 4s 151ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.2, score=1.000, total=  15.2s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.2 ......\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 10s 93ms/step - loss: 0.0766 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 752us/step - loss: 1.1063e-06 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 532us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 742us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 725us/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 819us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 724us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 913us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 780us/step - loss: 2.7088e-07 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.0076e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 3s 123ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.2, score=1.000, total=  14.5s\n",
      "[CV] batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.2 ......\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 9s 86ms/step - loss: 0.1046 - acc: 0.9808\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 831us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 682us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 692us/step - loss: 1.5066e-05 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 638us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 740us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 686us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 708us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 679us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 695us/step - loss: 0.0013 - acc: 1.0000\n",
      "26/26 [==============================] - 4s 137ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.2, epochs=10, learn_rate=0.2, score=1.000, total=  14.4s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.001 .....\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 9s 91ms/step - loss: 0.6875 - acc: 0.7596\n",
      "26/26 [==============================] - 3s 128ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.001, score=0.962, total=  13.6s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.001 .....\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 9s 89ms/step - loss: 0.6946 - acc: 0.6058\n",
      "26/26 [==============================] - 4s 157ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.001, score=1.000, total=  14.3s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.001 .....\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 11s 103ms/step - loss: 0.6745 - acc: 1.0000\n",
      "26/26 [==============================] - 4s 142ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.001, score=1.000, total=  15.6s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.001 .....\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 9s 89ms/step - loss: 0.6905 - acc: 0.8846\n",
      "26/26 [==============================] - 4s 139ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.001, score=0.962, total=  13.7s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.001 .....\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 10s 92ms/step - loss: 0.6880 - acc: 0.8654\n",
      "26/26 [==============================] - 4s 136ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.001, score=1.000, total=  14.0s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.02 ......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 10s 92ms/step - loss: 0.4932 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 4s 166ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.02, score=1.000, total=  14.8s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.02 ......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 12s 111ms/step - loss: 0.5810 - acc: 0.9231\n",
      "26/26 [==============================] - 4s 142ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.02, score=1.000, total=  16.4s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.02 ......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 10s 94ms/step - loss: 0.4739 - acc: 1.0000\n",
      "26/26 [==============================] - 4s 146ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.02, score=1.000, total=  14.4s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.02 ......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 10s 100ms/step - loss: 0.5122 - acc: 0.9904\n",
      "26/26 [==============================] - 4s 152ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.02, score=1.000, total=  15.2s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.02 ......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 11s 102ms/step - loss: 0.6480 - acc: 0.9423\n",
      "26/26 [==============================] - 5s 184ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.02, score=1.000, total=  16.3s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 12s 112ms/step - loss: 0.3703 - acc: 0.9712\n",
      "26/26 [==============================] - 4s 148ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.2, score=1.000, total=  16.5s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 10s 99ms/step - loss: 0.1215 - acc: 0.9904\n",
      "26/26 [==============================] - 4s 153ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.2, score=1.000, total=  15.1s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 11s 104ms/step - loss: 0.2188 - acc: 0.9519\n",
      "26/26 [==============================] - 4s 160ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.2, score=1.000, total=  15.8s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 12s 118ms/step - loss: 0.1481 - acc: 0.9808\n",
      "26/26 [==============================] - 5s 191ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.2, score=1.000, total=  18.1s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 11s 110ms/step - loss: 0.1829 - acc: 0.9808\n",
      "26/26 [==============================] - 4s 164ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=1, learn_rate=0.2, score=1.000, total=  16.8s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 11s 107ms/step - loss: 0.6828 - acc: 0.8942\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 761us/step - loss: 0.6672 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 773us/step - loss: 0.6519 - acc: 0.9904\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 840us/step - loss: 0.6338 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 820us/step - loss: 0.6228 - acc: 1.0000\n",
      "26/26 [==============================] - 4s 164ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.001, score=1.000, total=  16.6s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 11s 109ms/step - loss: 0.6855 - acc: 0.9135\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 697us/step - loss: 0.6746 - acc: 0.9904\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 745us/step - loss: 0.6564 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 690us/step - loss: 0.6448 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 832us/step - loss: 0.6242 - acc: 1.0000 0s - loss: 0.6232 - acc: 1.000\n",
      "26/26 [==============================] - 5s 178ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.001, score=1.000, total=  17.2s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 13s 128ms/step - loss: 0.6819 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 953us/step - loss: 0.6604 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 793us/step - loss: 0.6416 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 732us/step - loss: 0.6180 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 991us/step - loss: 0.5999 - acc: 1.0000\n",
      "26/26 [==============================] - 4s 168ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.001, score=1.000, total=  19.0s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 11s 109ms/step - loss: 0.6940 - acc: 0.7115\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 760us/step - loss: 0.6840 - acc: 0.9231\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 851us/step - loss: 0.6739 - acc: 0.9904\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 953us/step - loss: 0.6643 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 736us/step - loss: 0.6546 - acc: 1.0000\n",
      "26/26 [==============================] - 4s 169ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.001, score=1.000, total=  17.0s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.6826 - acc: 0.9327\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 822us/step - loss: 0.6667 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 868us/step - loss: 0.6470 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 825us/step - loss: 0.6227 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 833us/step - loss: 0.6071 - acc: 1.0000\n",
      "26/26 [==============================] - 4s 171ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.001, score=1.000, total=  17.4s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 14s 139ms/step - loss: 0.5221 - acc: 0.9712\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 967us/step - loss: 0.1489 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0579 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 979us/step - loss: 0.0441 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0493 - acc: 1.0000\n",
      "26/26 [==============================] - 5s 203ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.02, score=1.000, total=  21.0s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 12s 113ms/step - loss: 0.5196 - acc: 0.9808\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 694us/step - loss: 0.1391 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0583 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 906us/step - loss: 0.0321 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 943us/step - loss: 0.0434 - acc: 1.0000\n",
      "26/26 [==============================] - 5s 179ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.02, score=1.000, total=  17.8s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 13s 125ms/step - loss: 0.5703 - acc: 0.9327\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 655us/step - loss: 0.2555 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 858us/step - loss: 0.1397 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 906us/step - loss: 0.0753 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 813us/step - loss: 0.0755 - acc: 1.0000\n",
      "26/26 [==============================] - 5s 176ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.02, score=1.000, total=  18.8s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 13s 126ms/step - loss: 0.5151 - acc: 0.9423\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2202 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1278 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1095 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 964us/step - loss: 0.0524 - acc: 1.0000\n",
      "26/26 [==============================] - 7s 260ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.02, score=1.000, total=  21.1s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 22s 207ms/step - loss: 0.6232 - acc: 0.9519\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4227 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2640 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1369 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1349 - acc: 1.0000\n",
      "26/26 [==============================] - 7s 250ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.02, score=1.000, total=  30.3s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 13s 125ms/step - loss: 0.0880 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 927us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 917us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 826us/step - loss: 0.0028 - acc: 1.0000\n",
      "26/26 [==============================] - 7s 268ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.2, score=1.000, total=  21.6s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 20s 194ms/step - loss: 0.1243 - acc: 0.9712\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 928us/step - loss: 0.0256 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 877us/step - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 744us/step - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 711us/step - loss: 0.0054 - acc: 1.0000\n",
      "26/26 [==============================] - 5s 207ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.2, score=1.000, total=  28.1s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 13s 125ms/step - loss: 0.3014 - acc: 0.9231\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 809us/step - loss: 0.0342 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 786us/step - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 768us/step - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 986us/step - loss: 0.0087 - acc: 1.0000\n",
      "26/26 [==============================] - 5s 190ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.2, score=1.000, total=  19.3s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 15s 141ms/step - loss: 0.1427 - acc: 0.9615\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0075 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000\n",
      "26/26 [==============================] - 7s 256ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.2, score=1.000, total=  22.8s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 13s 129ms/step - loss: 0.3703 - acc: 0.9327\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 849us/step - loss: 0.0707 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 857us/step - loss: 0.0239 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 861us/step - loss: 0.0133 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 907us/step - loss: 0.0096 - acc: 1.0000\n",
      "26/26 [==============================] - 5s 204ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=5, learn_rate=0.2, score=1.000, total=  20.5s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 14s 133ms/step - loss: 0.6909 - acc: 0.7115\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 812us/step - loss: 0.6774 - acc: 0.9808\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 896us/step - loss: 0.6673 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 918us/step - loss: 0.6550 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.6382 - acc: 1.000 - 0s 687us/step - loss: 0.6393 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 926us/step - loss: 0.6227 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 929us/step - loss: 0.6132 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 882us/step - loss: 0.5922 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.5839 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.5571 - acc: 1.0000\n",
      "26/26 [==============================] - 5s 197ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.001, score=1.000, total=  20.7s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 15s 147ms/step - loss: 0.6828 - acc: 0.9519\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6616 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 781us/step - loss: 0.6407 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6127 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 985us/step - loss: 0.5924 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.5574 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.5285 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4844 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4651 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4387 - acc: 1.0000\n",
      "26/26 [==============================] - 7s 273ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.001, score=1.000, total=  24.3s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 19s 179ms/step - loss: 0.6845 - acc: 0.8462\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6574 - acc: 0.9904\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6401 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 890us/step - loss: 0.6190 - acc: 1.0000\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 900us/step - loss: 0.5899 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 751us/step - loss: 0.5718 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 975us/step - loss: 0.5442 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 850us/step - loss: 0.5175 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 925us/step - loss: 0.4807 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 868us/step - loss: 0.4539 - acc: 1.0000\n",
      "26/26 [==============================] - 5s 199ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.001, score=1.000, total=  26.7s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 15s 144ms/step - loss: 0.6919 - acc: 0.8173\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6852 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 804us/step - loss: 0.6793 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 970us/step - loss: 0.6733 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 906us/step - loss: 0.6669 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6605 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 985us/step - loss: 0.6524 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 994us/step - loss: 0.6445 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 976us/step - loss: 0.6380 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 843us/step - loss: 0.6265 - acc: 1.0000\n",
      "26/26 [==============================] - 7s 272ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.001, score=1.000, total=  23.9s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 17s 161ms/step - loss: 0.6880 - acc: 0.8942\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 811us/step - loss: 0.6734 - acc: 0.9904\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6533 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 871us/step - loss: 0.6306 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6054 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 893us/step - loss: 0.5876 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 965us/step - loss: 0.5661 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 986us/step - loss: 0.5446 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.5029 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4763 - acc: 1.0000\n",
      "26/26 [==============================] - 6s 233ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.001, score=1.000, total=  25.0s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 16s 154ms/step - loss: 0.5569 - acc: 0.9904\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1699 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 928us/step - loss: 0.0510 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 975us/step - loss: 0.0387 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0200 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0410 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 878us/step - loss: 0.0298 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 936us/step - loss: 0.0131 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 966us/step - loss: 0.0327 - acc: 1.0000\n",
      "26/26 [==============================] - 6s 245ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.02, score=1.000, total=  24.3s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 24s 229ms/step - loss: 0.5354 - acc: 0.9904\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 890us/step - loss: 0.2119 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 837us/step - loss: 0.1049 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0883 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0660 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0683 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0679 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0671 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0393 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0629 - acc: 1.0000\n",
      "26/26 [==============================] - 6s 231ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.02, score=1.000, total=  32.1s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 17s 165ms/step - loss: 0.5177 - acc: 0.9615\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 942us/step - loss: 0.1997 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1225 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0809 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0933 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0756 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0383 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0501 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0494 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0473 - acc: 1.0000\n",
      "26/26 [==============================] - 7s 274ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.02, score=1.000, total=  26.4s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 19s 185ms/step - loss: 0.5318 - acc: 0.9712\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1804 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1187 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 908us/step - loss: 0.1000 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 939us/step - loss: 0.0604 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 887us/step - loss: 0.0729 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 869us/step - loss: 0.1029 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 928us/step - loss: 0.0490 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 919us/step - loss: 0.0412 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 908us/step - loss: 0.0409 - acc: 1.0000\n",
      "26/26 [==============================] - 6s 215ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.02, score=1.000, total=  27.0s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 16s 159ms/step - loss: 0.6042 - acc: 0.9712\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 880us/step - loss: 0.3775 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2017 - acc: 1.0000\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1776 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1612 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1351 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1323 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1223 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1136 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 983us/step - loss: 0.1040 - acc: 1.0000\n",
      "26/26 [==============================] - 6s 238ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.02, score=1.000, total=  24.9s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.2 ......\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 17s 164ms/step - loss: 0.3749 - acc: 0.9231\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0711 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0241 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 988us/step - loss: 0.0135 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0097 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 935us/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 902us/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 969us/step - loss: 0.0046 - acc: 1.0000\n",
      "26/26 [==============================] - 7s 262ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.2, score=1.000, total=  25.9s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.2 ......\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 17s 167ms/step - loss: 0.1026 - acc: 0.9808\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 982us/step - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 995us/step - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 844us/step - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 926us/step - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 882us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0033 - acc: 1.0000\n",
      "26/26 [==============================] - 6s 235ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.2, score=1.000, total=  25.5s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.2 ......\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 16s 154ms/step - loss: 0.2486 - acc: 0.9231\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0392 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0190 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 921us/step - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 941us/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0037 - acc: 1.0000\n",
      "26/26 [==============================] - 8s 297ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.2, score=1.000, total=  25.6s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.2 ......\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 18s 175ms/step - loss: 0.1632 - acc: 0.9327\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 947us/step - loss: 0.0235 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 975us/step - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 958us/step - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 994us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0031 - acc: 1.0000\n",
      "26/26 [==============================] - 7s 284ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.2, score=1.000, total=  27.9s\n",
      "[CV] batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.2 ......\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 18s 170ms/step - loss: 0.1692 - acc: 0.9327\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 971us/step - loss: 0.0246 - acc: 1.0000 0s - loss: 0.0275 - acc: 1.000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 893us/step - loss: 0.0126 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0113 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 892us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 946us/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0031 - acc: 1.0000\n",
      "26/26 [==============================] - 6s 241ms/step\n",
      "[CV]  batch_size=10, dropout_rate=0.4, epochs=10, learn_rate=0.2, score=1.000, total=  26.1s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 19s 187ms/step - loss: 0.6858 - acc: 0.9327\n",
      "26/26 [==============================] - 7s 268ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=1.000, total=  27.3s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 18s 170ms/step - loss: 0.6871 - acc: 0.7885\n",
      "26/26 [==============================] - 6s 239ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=1.000, total=  24.8s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 19s 181ms/step - loss: 0.6933 - acc: 0.6346\n",
      "26/26 [==============================] - 7s 264ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=0.962, total=  26.6s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 18s 174ms/step - loss: 0.6902 - acc: 0.6731\n",
      "26/26 [==============================] - 6s 244ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=0.923, total=  25.2s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.001 .....\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 18s 174ms/step - loss: 0.6920 - acc: 0.8365\n",
      "26/26 [==============================] - 8s 301ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.001, score=1.000, total=  26.7s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 18s 173ms/step - loss: 0.6039 - acc: 0.9231\n",
      "26/26 [==============================] - 6s 238ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=1.000, total=  25.0s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 17s 168ms/step - loss: 0.5987 - acc: 1.0000\n",
      "26/26 [==============================] - 7s 282ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=1.000, total=  25.6s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 19s 187ms/step - loss: 0.6077 - acc: 0.9615\n",
      "26/26 [==============================] - 6s 242ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=1.000, total=  26.6s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 18s 169ms/step - loss: 0.6687 - acc: 0.8462\n",
      "26/26 [==============================] - 7s 272ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=1.000, total=  25.3s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.02 ......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 21s 199ms/step - loss: 0.6123 - acc: 0.8558\n",
      "26/26 [==============================] - 7s 255ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.02, score=1.000, total=  28.1s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 18s 170ms/step - loss: 0.2079 - acc: 0.9904\n",
      "26/26 [==============================] - 7s 261ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.2, score=1.000, total=  25.3s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 21s 206ms/step - loss: 0.1639 - acc: 0.9615\n",
      "26/26 [==============================] - 8s 314ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.2, score=1.000, total=  30.3s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 18s 176ms/step - loss: 0.2565 - acc: 0.9038\n",
      "26/26 [==============================] - 7s 278ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.2, score=1.000, total=  26.3s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 20s 195ms/step - loss: 0.2239 - acc: 0.9038\n",
      "26/26 [==============================] - 8s 300ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.2, score=1.000, total=  29.1s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 18s 176ms/step - loss: 0.2682 - acc: 0.8077\n",
      "26/26 [==============================] - 7s 262ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=1, learn_rate=0.2, score=1.000, total=  26.0s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 18s 177ms/step - loss: 0.6946 - acc: 0.4808\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 958us/step - loss: 0.6898 - acc: 0.9327\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 860us/step - loss: 0.6859 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 854us/step - loss: 0.6825 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 998us/step - loss: 0.6790 - acc: 1.0000\n",
      "26/26 [==============================] - 8s 304ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.001, score=1.000, total=  27.5s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 19s 185ms/step - loss: 0.6859 - acc: 0.9712\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 788us/step - loss: 0.6763 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 568us/step - loss: 0.6650 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 757us/step - loss: 0.6523 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 581us/step - loss: 0.6382 - acc: 1.0000\n",
      "26/26 [==============================] - 7s 268ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.001, score=1.000, total=  27.3s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 19s 180ms/step - loss: 0.6940 - acc: 0.4231\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 782us/step - loss: 0.6898 - acc: 0.9808\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 532us/step - loss: 0.6865 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 524us/step - loss: 0.6835 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 626us/step - loss: 0.6805 - acc: 1.0000\n",
      "26/26 [==============================] - 7s 287ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.001, score=1.000, total=  27.2s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 20s 197ms/step - loss: 0.6845 - acc: 0.9423\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 696us/step - loss: 0.6723 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 544us/step - loss: 0.6576 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 684us/step - loss: 0.6418 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 702us/step - loss: 0.6251 - acc: 1.0000\n",
      "26/26 [==============================] - 7s 276ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.001, score=1.000, total=  28.9s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 19s 181ms/step - loss: 0.6936 - acc: 0.5865\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 926us/step - loss: 0.6856 - acc: 0.9423\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 809us/step - loss: 0.6778 - acc: 0.9904\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 757us/step - loss: 0.6701 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 756us/step - loss: 0.6622 - acc: 1.0000\n",
      "26/26 [==============================] - 7s 273ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.001, score=1.000, total=  27.1s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 22s 212ms/step - loss: 0.6614 - acc: 0.8846\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.5251 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.3017 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 966us/step - loss: 0.0927 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 878us/step - loss: 0.0171 - acc: 1.0000\n",
      "26/26 [==============================] - 10s 370ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.02, score=1.000, total=  32.9s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 20s 193ms/step - loss: 0.6676 - acc: 0.8462\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 996us/step - loss: 0.5596 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 963us/step - loss: 0.3978 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 896us/step - loss: 0.2006 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 918us/step - loss: 0.0625 - acc: 1.0000\n",
      "26/26 [==============================] - 8s 292ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.02, score=1.000, total=  28.9s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.02 ......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "104/104 [==============================] - 22s 209ms/step - loss: 0.6307 - acc: 0.9712\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 687us/step - loss: 0.3934 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 594us/step - loss: 0.1458 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 551us/step - loss: 0.0310 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 639us/step - loss: 0.0055 - acc: 1.0000\n",
      "26/26 [==============================] - 8s 293ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.02, score=1.000, total=  30.4s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 20s 194ms/step - loss: 0.6399 - acc: 0.8558\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 668us/step - loss: 0.4293 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 571us/step - loss: 0.1783 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 600us/step - loss: 0.0423 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 562us/step - loss: 0.0074 - acc: 1.0000\n",
      "26/26 [==============================] - 8s 299ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.02, score=1.000, total=  29.1s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 22s 215ms/step - loss: 0.6219 - acc: 0.9231\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 644us/step - loss: 0.3646 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 540us/step - loss: 0.1370 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 645us/step - loss: 0.0301 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 658us/step - loss: 0.0049 - acc: 1.0000\n",
      "26/26 [==============================] - 8s 302ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.02, score=1.000, total=  31.3s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 20s 192ms/step - loss: 0.2064 - acc: 0.9615\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 647us/step - loss: 1.3253e-06 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 676us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 619us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 549us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 8s 303ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.2, score=1.000, total=  29.7s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 22s 209ms/step - loss: 0.2823 - acc: 0.8942\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 656us/step - loss: 1.2668e-05 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 667us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 629us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 628us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 8s 314ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.2, score=1.000, total=  31.1s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 20s 193ms/step - loss: 0.1633 - acc: 0.9712\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 827us/step - loss: 1.0066e-07 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 609us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 603us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 610us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 8s 295ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.2, score=1.000, total=  28.8s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 28s 273ms/step - loss: 0.2098 - acc: 1.0000\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 819us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 893us/step - loss: 1.0000e-07 - acc: 1.0000 0s - loss: 1.0000e-07 - acc: 1.000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 937us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 13s 501ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.2, score=1.000, total=  42.8s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 33s 320ms/step - loss: 0.3236 - acc: 0.8462\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 7.1751e-05 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.0162e-07 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 12s 445ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=5, learn_rate=0.2, score=1.000, total=  47.6s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 21s 201ms/step - loss: 0.6959 - acc: 0.4231\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 651us/step - loss: 0.6864 - acc: 0.9519\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 552us/step - loss: 0.6790 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 683us/step - loss: 0.6718 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 671us/step - loss: 0.6643 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 753us/step - loss: 0.6567 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 676us/step - loss: 0.6486 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 636us/step - loss: 0.6402 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 655us/step - loss: 0.6313 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 657us/step - loss: 0.6217 - acc: 1.0000\n",
      "26/26 [==============================] - 8s 306ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.001, score=1.000, total=  30.3s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 26s 252ms/step - loss: 0.6903 - acc: 0.9231\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 824us/step - loss: 0.6837 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 982us/step - loss: 0.6761 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 854us/step - loss: 0.6677 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6588 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6492 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 829us/step - loss: 0.6388 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 974us/step - loss: 0.6267 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6123 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 791us/step - loss: 0.5963 - acc: 1.0000\n",
      "26/26 [==============================] - 9s 356ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.001, score=1.000, total=  37.4s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 21s 203ms/step - loss: 0.6870 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 894us/step - loss: 0.6784 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 988us/step - loss: 0.6689 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 933us/step - loss: 0.6584 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 920us/step - loss: 0.6472 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 840us/step - loss: 0.6350 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 621us/step - loss: 0.6215 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 601us/step - loss: 0.6071 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 585us/step - loss: 0.5917 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 814us/step - loss: 0.5746 - acc: 1.0000\n",
      "26/26 [==============================] - 9s 338ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.001, score=1.000, total=  31.5s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 25s 236ms/step - loss: 0.6858 - acc: 0.9423\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 668us/step - loss: 0.6786 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 778us/step - loss: 0.6709 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 696us/step - loss: 0.6624 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 814us/step - loss: 0.6530 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 741us/step - loss: 0.6426 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 794us/step - loss: 0.6313 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 709us/step - loss: 0.6190 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 987us/step - loss: 0.6055 - acc: 1.0000 0s - loss: 0.6066 - acc: 1.000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 877us/step - loss: 0.5914 - acc: 1.0000\n",
      "26/26 [==============================] - 9s 358ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.001, score=1.000, total=  35.6s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 23s 217ms/step - loss: 0.6930 - acc: 0.7981\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 793us/step - loss: 0.6895 - acc: 0.9615\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 644us/step - loss: 0.6861 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 781us/step - loss: 0.6829 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 840us/step - loss: 0.6797 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 837us/step - loss: 0.6763 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 834us/step - loss: 0.6729 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6693 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 977us/step - loss: 0.6656 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 895us/step - loss: 0.6617 - acc: 1.0000\n",
      "26/26 [==============================] - 9s 336ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.001, score=1.000, total=  32.8s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 22s 213ms/step - loss: 0.5708 - acc: 0.9712\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 662us/step - loss: 0.2078 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 637us/step - loss: 0.0321 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 707us/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 655us/step - loss: 5.6578e-04 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 636us/step - loss: 1.8723e-04 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 626us/step - loss: 6.9153e-05 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 629us/step - loss: 4.3776e-05 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 638us/step - loss: 3.3398e-05 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 599us/step - loss: 2.7930e-05 - acc: 1.0000\n",
      "26/26 [==============================] - 8s 303ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=1.000, total=  31.4s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 23s 220ms/step - loss: 0.6132 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 790us/step - loss: 0.2957 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 908us/step - loss: 0.0647 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 552us/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 901us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 574us/step - loss: 2.5698e-04 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 822us/step - loss: 1.1211e-04 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 931us/step - loss: 6.2355e-05 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 853us/step - loss: 4.6168e-05 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 765us/step - loss: 3.8584e-05 - acc: 1.0000\n",
      "26/26 [==============================] - 9s 359ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=1.000, total=  33.8s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 21s 205ms/step - loss: 0.6478 - acc: 0.9519\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 589us/step - loss: 0.4408 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 638us/step - loss: 0.1879 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 620us/step - loss: 0.0427 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 560us/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 760us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 630us/step - loss: 5.0145e-04 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 2.5224e-04 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 808us/step - loss: 1.5984e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.1736e-04 - acc: 1.0000\n",
      "26/26 [==============================] - 8s 299ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=1.000, total=  30.5s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 23s 221ms/step - loss: 0.6442 - acc: 0.9519\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 826us/step - loss: 0.4282 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 867us/step - loss: 0.1530 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 564us/step - loss: 0.0272 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 698us/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 640us/step - loss: 7.8595e-04 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 619us/step - loss: 2.7684e-04 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 638us/step - loss: 1.3021e-04 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 560us/step - loss: 8.8651e-05 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 672us/step - loss: 6.9404e-05 - acc: 1.0000\n",
      "26/26 [==============================] - 8s 296ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=1.000, total=  32.1s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.02 .....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 21s 207ms/step - loss: 0.6236 - acc: 0.9904\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 611us/step - loss: 0.3739 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 685us/step - loss: 0.1329 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 647us/step - loss: 0.0290 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 713us/step - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 585us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 808us/step - loss: 5.7769e-04 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 883us/step - loss: 3.1500e-04 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 874us/step - loss: 2.1471e-04 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 761us/step - loss: 1.6406e-04 - acc: 1.0000\n",
      "26/26 [==============================] - 8s 321ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.02, score=1.000, total=  31.2s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 23s 223ms/step - loss: 0.2240 - acc: 0.9808\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 654us/step - loss: 1.0829e-07 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 631us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 638us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 608us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 648us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 606us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 619us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 638us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 694us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 8s 308ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=1.000, total=  32.5s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 22s 215ms/step - loss: 0.1770 - acc: 0.8942\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 898us/step - loss: 1.0076e-07 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 788us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 739us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 910us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 779us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 869us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 981us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 9s 344ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=1.000, total=  33.0s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 23s 224ms/step - loss: 0.2409 - acc: 0.8558\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 748us/step - loss: 1.5974e-06 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 522us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 747us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 637us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 638us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 592us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 708us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 629us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 524us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 8s 309ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=1.000, total=  32.8s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 22s 213ms/step - loss: 0.2468 - acc: 0.8173\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 773us/step - loss: 1.0404e-06 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 524us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 708us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 819us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 608us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 616us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 593us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 655us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 903us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 10s 367ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=1.000, total=  33.0s\n",
      "[CV] batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.2 ......\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 23s 218ms/step - loss: 0.1975 - acc: 0.9615\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 665us/step - loss: 1.4112e-07 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 600us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 642us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 618us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 655us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 669us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 623us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 552us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 863us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "26/26 [==============================] - 8s 319ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.0, epochs=10, learn_rate=0.2, score=1.000, total=  32.6s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 23s 221ms/step - loss: 0.6885 - acc: 0.8846\n",
      "26/26 [==============================] - 10s 368ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=1.000, total=  33.5s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 22s 214ms/step - loss: 0.6953 - acc: 0.2404\n",
      "26/26 [==============================] - 8s 326ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=0.846, total=  31.6s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 24s 231ms/step - loss: 0.6867 - acc: 0.7885\n",
      "26/26 [==============================] - 9s 348ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=1.000, total=  33.9s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "104/104 [==============================] - 24s 232ms/step - loss: 0.6887 - acc: 0.7596\n",
      "26/26 [==============================] - 9s 328ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=0.923, total=  33.4s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.001 .....\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 25s 244ms/step - loss: 0.6876 - acc: 0.9904\n",
      "26/26 [==============================] - 9s 335ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.001, score=1.000, total=  34.9s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 23s 222ms/step - loss: 0.6417 - acc: 0.9808\n",
      "26/26 [==============================] - 9s 345ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=1.000, total=  32.9s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 26s 245ms/step - loss: 0.6734 - acc: 0.8365\n",
      "26/26 [==============================] - 9s 336ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=1.000, total=  35.3s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 24s 228ms/step - loss: 0.5640 - acc: 1.0000\n",
      "26/26 [==============================] - 10s 388ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=1.000, total=  34.7s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 24s 232ms/step - loss: 0.6753 - acc: 0.8173\n",
      "26/26 [==============================] - 9s 346ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=1.000, total=  34.1s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.02 ......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 25s 243ms/step - loss: 0.5645 - acc: 0.9808\n",
      "26/26 [==============================] - 9s 354ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.02, score=1.000, total=  35.3s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 24s 234ms/step - loss: 0.5176 - acc: 0.8173\n",
      "26/26 [==============================] - 9s 347ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=1.000, total=  34.2s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 26s 250ms/step - loss: 0.3263 - acc: 0.9231\n",
      "26/26 [==============================] - 9s 346ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=1.000, total=  36.0s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 25s 236ms/step - loss: 0.2359 - acc: 0.8942\n",
      "26/26 [==============================] - 10s 390ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=1.000, total=  35.6s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 26s 247ms/step - loss: 0.1987 - acc: 0.9712\n",
      "26/26 [==============================] - 9s 351ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=1.000, total=  35.9s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.2 .......\n",
      "Epoch 1/1\n",
      "104/104 [==============================] - 28s 269ms/step - loss: 0.1943 - acc: 0.9615\n",
      "26/26 [==============================] - 12s 458ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=1, learn_rate=0.2, score=1.000, total=  40.8s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 27s 255ms/step - loss: 0.6877 - acc: 0.9327\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 771us/step - loss: 0.6803 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 898us/step - loss: 0.6722 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 932us/step - loss: 0.6617 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6527 - acc: 1.0000\n",
      "26/26 [==============================] - 10s 382ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=1.000, total=  37.7s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 28s 273ms/step - loss: 0.6875 - acc: 0.9904\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 819us/step - loss: 0.6762 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 849us/step - loss: 0.6647 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 859us/step - loss: 0.6494 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 767us/step - loss: 0.6330 - acc: 1.0000\n",
      "26/26 [==============================] - 10s 371ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=1.000, total=  39.7s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 27s 262ms/step - loss: 0.6913 - acc: 0.7019\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 942us/step - loss: 0.6808 - acc: 0.9231\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 938us/step - loss: 0.6680 - acc: 0.9904\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 857us/step - loss: 0.6585 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 945us/step - loss: 0.6433 - acc: 1.0000\n",
      "26/26 [==============================] - 10s 397ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=1.000, total=  38.8s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 26s 253ms/step - loss: 0.6846 - acc: 0.9615\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 958us/step - loss: 0.6760 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 968us/step - loss: 0.6655 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 808us/step - loss: 0.6540 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 926us/step - loss: 0.6403 - acc: 1.0000\n",
      "26/26 [==============================] - 10s 380ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=1.000, total=  37.7s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.001 .....\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 29s 278ms/step - loss: 0.6925 - acc: 0.6827\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 803us/step - loss: 0.6855 - acc: 0.9519\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 819us/step - loss: 0.6781 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 783us/step - loss: 0.6706 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 797us/step - loss: 0.6638 - acc: 1.0000\n",
      "26/26 [==============================] - 10s 379ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.001, score=1.000, total=  40.0s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 29s 280ms/step - loss: 0.6581 - acc: 0.8269\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 982us/step - loss: 0.4984 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 879us/step - loss: 0.3018 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 828us/step - loss: 0.2075 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 937us/step - loss: 0.1042 - acc: 1.0000\n",
      "26/26 [==============================] - 12s 448ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=1.000, total=  42.1s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 27s 262ms/step - loss: 0.6013 - acc: 0.9712\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2950 - acc: 1.0000\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0751 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 946us/step - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 684us/step - loss: 0.0120 - acc: 1.0000\n",
      "26/26 [==============================] - 10s 380ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=1.000, total=  38.4s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 30s 284ms/step - loss: 0.5862 - acc: 0.9712\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 562us/step - loss: 0.2678 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 834us/step - loss: 0.0866 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0271 - acc: 1.000 - 0s 710us/step - loss: 0.0429 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0220 - acc: 1.0000\n",
      "26/26 [==============================] - 10s 395ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=1.000, total=  41.0s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 29s 279ms/step - loss: 0.6472 - acc: 0.8846\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 815us/step - loss: 0.4721 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 869us/step - loss: 0.3093 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 842us/step - loss: 0.1933 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 803us/step - loss: 0.1200 - acc: 1.0000\n",
      "26/26 [==============================] - 11s 425ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=1.000, total=  41.3s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.02 ......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 28s 268ms/step - loss: 0.6421 - acc: 0.9519\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 654us/step - loss: 0.4204 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 938us/step - loss: 0.1911 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 842us/step - loss: 0.0991 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 893us/step - loss: 0.0451 - acc: 1.0000\n",
      "26/26 [==============================] - 10s 403ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.02, score=1.000, total=  39.6s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 30s 284ms/step - loss: 0.3118 - acc: 0.8558\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 789us/step - loss: 0.0523 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 910us/step - loss: 0.0268 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 890us/step - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 888us/step - loss: 0.0152 - acc: 1.0000\n",
      "26/26 [==============================] - 10s 399ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=1.000, total=  41.4s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 30s 287ms/step - loss: 0.2034 - acc: 0.8942\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 890us/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 964us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 821us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 938us/step - loss: 0.0052 - acc: 1.0000\n",
      "26/26 [==============================] - 11s 429ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=1.000, total=  42.3s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 29s 279ms/step - loss: 0.3306 - acc: 0.8558\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0500 - acc: 1.0000A: 0s - loss: 0.0603 - acc: 1.000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0191 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 855us/step - loss: 0.0115 - acc: 1.0000\n",
      "26/26 [==============================] - 11s 429ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=1.000, total=  41.4s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 30s 290ms/step - loss: 0.1773 - acc: 0.9904\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 979us/step - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 878us/step - loss: 1.0000e-07 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.0022 - acc: 1.0000    - 0s 742us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 907us/step - loss: 0.0019 - acc: 1.0000\n",
      "26/26 [==============================] - 11s 416ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=1.000, total=  42.4s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.2 .......\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 32s 307ms/step - loss: 0.2877 - acc: 0.9231\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 0s 971us/step - loss: 0.0208 - acc: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 0s 930us/step - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 0s 946us/step - loss: 0.0050 - acc: 1.0000\n",
      "26/26 [==============================] - 11s 439ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=5, learn_rate=0.2, score=1.000, total=  44.6s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 32s 304ms/step - loss: 0.6895 - acc: 0.7500\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 949us/step - loss: 0.6796 - acc: 0.9904\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 994us/step - loss: 0.6691 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 928us/step - loss: 0.6582 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 978us/step - loss: 0.6453 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6300 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 866us/step - loss: 0.6144 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.5996 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.5871 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.5664 - acc: 1.0000\n",
      "26/26 [==============================] - 13s 517ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=1.000, total=  48.5s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 33s 322ms/step - loss: 0.6886 - acc: 0.7692\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 772us/step - loss: 0.6793 - acc: 0.9808\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 791us/step - loss: 0.6697 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 878us/step - loss: 0.6578 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 982us/step - loss: 0.6463 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 945us/step - loss: 0.6365 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 976us/step - loss: 0.6196 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 837us/step - loss: 0.6162 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 777us/step - loss: 0.5936 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 967us/step - loss: 0.5855 - acc: 1.0000\n",
      "26/26 [==============================] - 13s 504ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=1.000, total=  48.4s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 33s 318ms/step - loss: 0.6906 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 930us/step - loss: 0.6853 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 999us/step - loss: 0.6785 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6707 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6631 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6531 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 964us/step - loss: 0.6421 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 765us/step - loss: 0.6333 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6199 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 880us/step - loss: 0.6081 - acc: 1.0000\n",
      "26/26 [==============================] - 12s 475ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=1.000, total=  47.5s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 37s 351ms/step - loss: 0.6912 - acc: 0.7308\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 713us/step - loss: 0.6843 - acc: 0.9615\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6762 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6682 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6607 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6524 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6458 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6347 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 916us/step - loss: 0.6272 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6102 - acc: 1.0000\n",
      "26/26 [==============================] - 13s 481ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=1.000, total=  51.1s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.001 ....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 36s 348ms/step - loss: 0.6812 - acc: 0.9231\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 752us/step - loss: 0.6669 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 834us/step - loss: 0.6554 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 940us/step - loss: 0.6443 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 912us/step - loss: 0.6327 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 1000us/step - loss: 0.6241 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 754us/step - loss: 0.6086 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 993us/step - loss: 0.5927 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 945us/step - loss: 0.5775 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 798us/step - loss: 0.5628 - acc: 1.0000\n",
      "26/26 [==============================] - 11s 438ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.001, score=1.000, total=  49.5s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 33s 313ms/step - loss: 0.6362 - acc: 0.9423\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4350 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.2347 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 946us/step - loss: 0.1090 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0391 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0412 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0255 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 893us/step - loss: 0.0210 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0189 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 932us/step - loss: 0.0178 - acc: 1.0000\n",
      "26/26 [==============================] - 12s 460ms/step\n",
      "[CV]  batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.02, score=1.000, total=  46.4s\n",
      "[CV] batch_size=20, dropout_rate=0.2, epochs=10, learn_rate=0.02 .....\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 32s 307ms/step - loss: 0.6486 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4247 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1487 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0342 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 7.7515e-04 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 995us/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 6.0104e-04 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters that you wish to use in your Grid Search along\n",
    "# with the list of values that you wish to try out\n",
    "learn_rate = [0.001, 0.02, 0.2]\n",
    "dropout_rate = [0.0, 0.2, 0.4]\n",
    "batch_size = [10, 20, 30]\n",
    "epochs = [1, 5, 10]\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grid = dict(\n",
    "    learn_rate=learn_rate,\n",
    "    dropout_rate=dropout_rate,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    ")\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "grid = GridSearchCV(\n",
    "    estimator=model, param_grid=param_grid, cv=KFold(random_state=seed), verbose=10\n",
    ")\n",
    "\n",
    "grid_results = grid.fit(X_standardized, Y)\n",
    "\n",
    "# Summarize the results in a readable format\n",
    "print(\n",
    "    \"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_)\n",
    ")\n",
    "\n",
    "means = grid_results.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_results.cv_results_[\"std_test_score\"]\n",
    "params = grid_results.cv_results_[\"params\"]\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"{0} ({1}) with: {2}\".format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.729167 using {'batch_size': 10, 'epochs': 100}\n",
      "0.524740 (0.137158) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.674479 (0.018136) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.729167 (0.003683) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.582031 (0.036225) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.559896 (0.132940) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.591146 (0.189559) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.582031 (0.052698) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.561198 (0.168327) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.699219 (0.028348) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.567708 (0.004872) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.671875 (0.032369) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.662760 (0.033197) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.526042 (0.119693) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.604167 (0.027126) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.660156 (0.008438) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.601562 (0.033754) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.475260 (0.118368) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.558594 (0.126577) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    # Compile model\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:, 8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_result.cv_results_[\"std_test_score\"]\n",
    "params = grid_result.cv_results_[\"params\"]\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Optimization Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.735677 using {'optimizer': 'Adam'}\n",
      "0.651042 (0.024774) with: {'optimizer': 'SGD'}\n",
      "0.696615 (0.019488) with: {'optimizer': 'RMSprop'}\n",
      "0.677083 (0.001841) with: {'optimizer': 'Adagrad'}\n",
      "0.651042 (0.050664) with: {'optimizer': 'Adadelta'}\n",
      "0.735677 (0.041626) with: {'optimizer': 'Adam'}\n",
      "0.630208 (0.052634) with: {'optimizer': 'Adamax'}\n",
      "0.597656 (0.152927) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer=\"adam\"):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    # Compile model\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:, 8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "optimizer = [\"SGD\", \"RMSprop\", \"Adagrad\", \"Adadelta\", \"Adam\", \"Adamax\", \"Nadam\"]\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_result.cv_results_[\"std_test_score\"]\n",
    "params = grid_result.cv_results_[\"params\"]\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Learning Rate and Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.664063 using {'learn_rate': 0.001, 'momentum': 0.6}\n",
      "0.549479 (0.122962) with: {'learn_rate': 0.001, 'momentum': 0.0}\n",
      "0.350260 (0.026557) with: {'learn_rate': 0.001, 'momentum': 0.2}\n",
      "0.658854 (0.012890) with: {'learn_rate': 0.001, 'momentum': 0.4}\n",
      "0.664063 (0.037603) with: {'learn_rate': 0.001, 'momentum': 0.6}\n",
      "0.656250 (0.030425) with: {'learn_rate': 0.001, 'momentum': 0.8}\n",
      "0.660156 (0.030758) with: {'learn_rate': 0.001, 'momentum': 0.9}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.01, 'momentum': 0.0}\n",
      "0.544271 (0.146518) with: {'learn_rate': 0.01, 'momentum': 0.2}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.01, 'momentum': 0.4}\n",
      "0.427083 (0.134575) with: {'learn_rate': 0.01, 'momentum': 0.6}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.01, 'momentum': 0.8}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.01, 'momentum': 0.9}\n",
      "0.572917 (0.134575) with: {'learn_rate': 0.1, 'momentum': 0.0}\n",
      "0.466146 (0.149269) with: {'learn_rate': 0.1, 'momentum': 0.2}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.1, 'momentum': 0.4}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.1, 'momentum': 0.6}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.1, 'momentum': 0.8}\n",
      "0.455729 (0.146518) with: {'learn_rate': 0.1, 'momentum': 0.9}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.2, 'momentum': 0.0}\n",
      "0.572917 (0.134575) with: {'learn_rate': 0.2, 'momentum': 0.2}\n",
      "0.533854 (0.149269) with: {'learn_rate': 0.2, 'momentum': 0.4}\n",
      "0.572917 (0.134575) with: {'learn_rate': 0.2, 'momentum': 0.6}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.2, 'momentum': 0.8}\n",
      "0.572917 (0.134575) with: {'learn_rate': 0.2, 'momentum': 0.9}\n",
      "0.533854 (0.149269) with: {'learn_rate': 0.3, 'momentum': 0.0}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.3, 'momentum': 0.2}\n",
      "0.348958 (0.024774) with: {'learn_rate': 0.3, 'momentum': 0.4}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.3, 'momentum': 0.6}\n",
      "0.651042 (0.024774) with: {'learn_rate': 0.3, 'momentum': 0.8}\n",
      "0.572917 (0.134575) with: {'learn_rate': 0.3, 'momentum': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Use scikit-learn to grid search the learning rate and momentum\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(learn_rate=0.01, momentum=0):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    # Compile model\n",
    "    optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:, 8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_result.cv_results_[\"std_test_score\"]\n",
    "params = grid_result.cv_results_[\"params\"]\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Network Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.730469 using {'init_mode': 'uniform'}\n",
      "0.730469 (0.017758) with: {'init_mode': 'uniform'}\n",
      "0.710938 (0.008438) with: {'init_mode': 'lecun_uniform'}\n",
      "0.727865 (0.016053) with: {'init_mode': 'normal'}\n",
      "0.651042 (0.024774) with: {'init_mode': 'zero'}\n",
      "0.688802 (0.033502) with: {'init_mode': 'glorot_normal'}\n",
      "0.550781 (0.164712) with: {'init_mode': 'glorot_uniform'}\n",
      "0.657552 (0.067231) with: {'init_mode': 'he_normal'}\n",
      "0.679688 (0.015947) with: {'init_mode': 'he_uniform'}\n"
     ]
    }
   ],
   "source": [
    "# Use scikit-learn to grid search the weight initialization\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(init_mode=\"uniform\"):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, kernel_initializer=init_mode, activation=\"relu\"))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation=\"sigmoid\"))\n",
    "    # Compile model\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:, 8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "init_mode = [\n",
    "    \"uniform\",\n",
    "    \"lecun_uniform\",\n",
    "    \"normal\",\n",
    "    \"zero\",\n",
    "    \"glorot_normal\",\n",
    "    \"glorot_uniform\",\n",
    "    \"he_normal\",\n",
    "    \"he_uniform\",\n",
    "]\n",
    "param_grid = dict(init_mode=init_mode)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_result.cv_results_[\"std_test_score\"]\n",
    "params = grid_result.cv_results_[\"params\"]\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the Neuron Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.734375 using {'activation': 'softplus'}\n",
      "0.634115 (0.018688) with: {'activation': 'softmax'}\n",
      "0.734375 (0.016877) with: {'activation': 'softplus'}\n",
      "0.701823 (0.011201) with: {'activation': 'softsign'}\n",
      "0.712240 (0.017566) with: {'activation': 'relu'}\n",
      "0.667969 (0.032369) with: {'activation': 'tanh'}\n",
      "0.692708 (0.014382) with: {'activation': 'sigmoid'}\n",
      "0.680990 (0.041134) with: {'activation': 'hard_sigmoid'}\n",
      "0.695313 (0.005524) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Use scikit-learn to grid search the activation function\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(activation=\"relu\"):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Dense(12, input_dim=8, kernel_initializer=\"uniform\", activation=activation)\n",
    "    )\n",
    "    model.add(Dense(1, kernel_initializer=\"uniform\", activation=\"sigmoid\"))\n",
    "    # Compile model\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:, 8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "activation = [\n",
    "    \"softmax\",\n",
    "    \"softplus\",\n",
    "    \"softsign\",\n",
    "    \"relu\",\n",
    "    \"tanh\",\n",
    "    \"sigmoid\",\n",
    "    \"hard_sigmoid\",\n",
    "    \"linear\",\n",
    "]\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_result.cv_results_[\"std_test_score\"]\n",
    "params = grid_result.cv_results_[\"params\"]\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Dropout Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Best: 0.734375 using {'dropout_rate': 0.1, 'weight_constraint': 1}\n",
      "0.718750 (0.026107) with: {'dropout_rate': 0.0, 'weight_constraint': 1}\n",
      "0.720052 (0.024150) with: {'dropout_rate': 0.0, 'weight_constraint': 2}\n",
      "0.716146 (0.004872) with: {'dropout_rate': 0.0, 'weight_constraint': 3}\n",
      "0.699219 (0.014616) with: {'dropout_rate': 0.0, 'weight_constraint': 4}\n",
      "0.730469 (0.022097) with: {'dropout_rate': 0.0, 'weight_constraint': 5}\n",
      "0.734375 (0.020915) with: {'dropout_rate': 0.1, 'weight_constraint': 1}\n",
      "0.723958 (0.024150) with: {'dropout_rate': 0.1, 'weight_constraint': 2}\n",
      "0.714844 (0.024910) with: {'dropout_rate': 0.1, 'weight_constraint': 3}\n",
      "0.705729 (0.008027) with: {'dropout_rate': 0.1, 'weight_constraint': 4}\n",
      "0.703125 (0.016877) with: {'dropout_rate': 0.1, 'weight_constraint': 5}\n",
      "0.718750 (0.011500) with: {'dropout_rate': 0.2, 'weight_constraint': 1}\n",
      "0.710938 (0.014616) with: {'dropout_rate': 0.2, 'weight_constraint': 2}\n",
      "0.710938 (0.009568) with: {'dropout_rate': 0.2, 'weight_constraint': 3}\n",
      "0.708333 (0.009744) with: {'dropout_rate': 0.2, 'weight_constraint': 4}\n",
      "0.708333 (0.003683) with: {'dropout_rate': 0.2, 'weight_constraint': 5}\n",
      "0.694010 (0.015073) with: {'dropout_rate': 0.3, 'weight_constraint': 1}\n",
      "0.716146 (0.029463) with: {'dropout_rate': 0.3, 'weight_constraint': 2}\n",
      "0.714844 (0.011049) with: {'dropout_rate': 0.3, 'weight_constraint': 3}\n",
      "0.708333 (0.008027) with: {'dropout_rate': 0.3, 'weight_constraint': 4}\n",
      "0.710938 (0.019401) with: {'dropout_rate': 0.3, 'weight_constraint': 5}\n",
      "0.721354 (0.023510) with: {'dropout_rate': 0.4, 'weight_constraint': 1}\n",
      "0.700521 (0.010253) with: {'dropout_rate': 0.4, 'weight_constraint': 2}\n",
      "0.688802 (0.019488) with: {'dropout_rate': 0.4, 'weight_constraint': 3}\n",
      "0.720052 (0.021710) with: {'dropout_rate': 0.4, 'weight_constraint': 4}\n",
      "0.712240 (0.035277) with: {'dropout_rate': 0.4, 'weight_constraint': 5}\n",
      "0.717448 (0.014731) with: {'dropout_rate': 0.5, 'weight_constraint': 1}\n",
      "0.712240 (0.027866) with: {'dropout_rate': 0.5, 'weight_constraint': 2}\n",
      "0.707031 (0.011049) with: {'dropout_rate': 0.5, 'weight_constraint': 3}\n",
      "0.709635 (0.006639) with: {'dropout_rate': 0.5, 'weight_constraint': 4}\n",
      "0.714844 (0.022326) with: {'dropout_rate': 0.5, 'weight_constraint': 5}\n",
      "0.712240 (0.010253) with: {'dropout_rate': 0.6, 'weight_constraint': 1}\n",
      "0.707031 (0.016573) with: {'dropout_rate': 0.6, 'weight_constraint': 2}\n",
      "0.713542 (0.028587) with: {'dropout_rate': 0.6, 'weight_constraint': 3}\n",
      "0.701823 (0.006639) with: {'dropout_rate': 0.6, 'weight_constraint': 4}\n",
      "0.709635 (0.012075) with: {'dropout_rate': 0.6, 'weight_constraint': 5}\n",
      "0.705729 (0.010253) with: {'dropout_rate': 0.7, 'weight_constraint': 1}\n",
      "0.707031 (0.011500) with: {'dropout_rate': 0.7, 'weight_constraint': 2}\n",
      "0.690104 (0.023939) with: {'dropout_rate': 0.7, 'weight_constraint': 3}\n",
      "0.701823 (0.003683) with: {'dropout_rate': 0.7, 'weight_constraint': 4}\n",
      "0.705729 (0.008027) with: {'dropout_rate': 0.7, 'weight_constraint': 5}\n",
      "0.688802 (0.022402) with: {'dropout_rate': 0.8, 'weight_constraint': 1}\n",
      "0.682292 (0.026748) with: {'dropout_rate': 0.8, 'weight_constraint': 2}\n",
      "0.694010 (0.032106) with: {'dropout_rate': 0.8, 'weight_constraint': 3}\n",
      "0.679688 (0.011500) with: {'dropout_rate': 0.8, 'weight_constraint': 4}\n",
      "0.674479 (0.011201) with: {'dropout_rate': 0.8, 'weight_constraint': 5}\n",
      "0.664063 (0.031412) with: {'dropout_rate': 0.9, 'weight_constraint': 1}\n",
      "0.657552 (0.031466) with: {'dropout_rate': 0.9, 'weight_constraint': 2}\n",
      "0.661458 (0.028940) with: {'dropout_rate': 0.9, 'weight_constraint': 3}\n",
      "0.665365 (0.016367) with: {'dropout_rate': 0.9, 'weight_constraint': 4}\n",
      "0.658854 (0.029635) with: {'dropout_rate': 0.9, 'weight_constraint': 5}\n"
     ]
    }
   ],
   "source": [
    "# Use scikit-learn to grid search the dropout rate\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(dropout_rate=0.0, weight_constraint=0):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Dense(\n",
    "            12,\n",
    "            input_dim=8,\n",
    "            kernel_initializer=\"uniform\",\n",
    "            activation=\"linear\",\n",
    "            kernel_constraint=maxnorm(weight_constraint),\n",
    "        )\n",
    "    )\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer=\"uniform\", activation=\"sigmoid\"))\n",
    "    # Compile model\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:, 8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "weight_constraint = [1, 2, 3, 4, 5]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_result.cv_results_[\"std_test_score\"]\n",
    "params = grid_result.cv_results_[\"params\"]\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the Number of Neurons in the Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.722656 using {'neurons': 15}\n",
      "0.708333 (0.009744) with: {'neurons': 1}\n",
      "0.701823 (0.009207) with: {'neurons': 5}\n",
      "0.718750 (0.026107) with: {'neurons': 10}\n",
      "0.722656 (0.028348) with: {'neurons': 15}\n",
      "0.705729 (0.003683) with: {'neurons': 20}\n",
      "0.717448 (0.008027) with: {'neurons': 25}\n",
      "0.713542 (0.006639) with: {'neurons': 30}\n"
     ]
    }
   ],
   "source": [
    "# Use scikit-learn to grid search the number of neurons\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(neurons=1):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Dense(\n",
    "            neurons,\n",
    "            input_dim=8,\n",
    "            kernel_initializer=\"uniform\",\n",
    "            activation=\"linear\",\n",
    "            kernel_constraint=maxnorm(4),\n",
    "        )\n",
    "    )\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, kernel_initializer=\"uniform\", activation=\"sigmoid\"))\n",
    "    # Compile model\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:, 8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "param_grid = dict(neurons=neurons)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_result.cv_results_[\"std_test_score\"]\n",
    "params = grid_result.cv_results_[\"params\"]\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import the dataset and view the top 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample Code Number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000026</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000027</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000028</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000029</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000030</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000031</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000032</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000033</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000034</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample Code Number  Clump Thickness  Uniformity of Cell Size  \\\n",
       "0             1000025                5                        1   \n",
       "1             1000026                5                        4   \n",
       "2             1000027                3                        1   \n",
       "3             1000028                6                        8   \n",
       "4             1000029                4                        1   \n",
       "5             1000030                8                       10   \n",
       "6             1000031                1                        1   \n",
       "7             1000032                2                        1   \n",
       "8             1000033                2                        1   \n",
       "9             1000034                4                        2   \n",
       "\n",
       "   Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "0                         1                  1                            2   \n",
       "1                         4                  5                            7   \n",
       "2                         1                  1                            2   \n",
       "3                         8                  1                            3   \n",
       "4                         1                  3                            2   \n",
       "5                        10                  8                            7   \n",
       "6                         1                  1                            2   \n",
       "7                         2                  1                            2   \n",
       "8                         1                  1                            2   \n",
       "9                         1                  1                            2   \n",
       "\n",
       "  Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0           1                3                1        1      2  \n",
       "1          10                3                2        1      2  \n",
       "2           2                3                1        1      2  \n",
       "3           4                3                7        1      2  \n",
       "4           1                3                1        1      2  \n",
       "5          10                9                7        1      4  \n",
       "6          10                3                1        1      2  \n",
       "7           1                3                1        1      2  \n",
       "8           1                1                1        5      2  \n",
       "9           1                2                1        1      2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import data\n",
    "data = pd.read_csv(\"breast-cancer-wisconsin.csv\", header=None)\n",
    "\n",
    "# set column names\n",
    "data.columns = [\n",
    "    \"Sample Code Number\",\n",
    "    \"Clump Thickness\",\n",
    "    \"Uniformity of Cell Size\",\n",
    "    \"Uniformity of Cell Shape\",\n",
    "    \"Marginal Adhesion\",\n",
    "    \"Single Epithelial Cell Size\",\n",
    "    \"Bare Nuclei\",\n",
    "    \"Bland Chromatin\",\n",
    "    \"Normal Nucleoli\",\n",
    "    \"Mitoses\",\n",
    "    \"Class\",\n",
    "]\n",
    "# view top 10 rows\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Clean the data and rename the class values as 0/1 for model building (where 1 represents a malignant case). Also, lets observe the distribution of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    444\n",
       "1    239\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop([\"Sample Code Number\"], axis=1)  # Drop 1st column\n",
    "data = data[data[\"Bare Nuclei\"] != \"?\"]  # Remove rows with missing data\n",
    "data[\"Class\"] = np.where(data[\"Class\"] == 2, 0, 1)  # Change the Class representation\n",
    "data[\"Class\"].value_counts()  # Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y actual : \n",
      "0    103\n",
      "1     68\n",
      "Name: Class, dtype: int64\n",
      "y predicted : \n",
      "0    171\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split data into attributes and class\n",
    "X = data.drop([\"Class\"], axis=1)\n",
    "y = data[\"Class\"]\n",
    "\n",
    "# perform training and test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Dummy Classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "clf = DummyClassifier(strategy=\"most_frequent\").fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Distribution of y test\n",
    "print(\"y actual : \\n\" + str(y_test.value_counts()))\n",
    "\n",
    "# Distribution of y predicted\n",
    "print(\"y predicted : \\n\" + str(pd.Series(y_pred).value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.6023391812865497\n",
      "Precision Score : 0.0\n",
      "Recall Score : 0.0\n",
      "F1 Score : 0.0\n",
      "Confusion Matrix : \n",
      "[[103   0]\n",
      " [ 68   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "print(\"Accuracy Score : \" + str(accuracy_score(y_test, y_pred)))\n",
    "print(\"Precision Score : \" + str(precision_score(y_test, y_pred)))\n",
    "print(\"Recall Score : \" + str(recall_score(y_test, y_pred)))\n",
    "print(\"F1 Score : \" + str(f1_score(y_test, y_pred)))\n",
    "\n",
    "# Dummy Classifier Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Confusion Matrix : \\n\" + str(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=(\"0\", \"1\"))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=(\"0\", \"1\"))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"red\")\n",
    "plt.title(\"Confusion Matrix - Dummy Classifier\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.9532163742690059\n",
      "Precision Score : 0.9838709677419355\n",
      "Recall Score : 0.8970588235294118\n",
      "F1 Score : 0.9384615384615386\n",
      "Confusion Matrix : \n",
      "[[102   1]\n",
      " [  7  61]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "print(\"Accuracy Score : \" + str(accuracy_score(y_test, y_pred)))\n",
    "print(\"Precision Score : \" + str(precision_score(y_test, y_pred)))\n",
    "print(\"Recall Score : \" + str(recall_score(y_test, y_pred)))\n",
    "print(\"F1 Score : \" + str(f1_score(y_test, y_pred)))\n",
    "\n",
    "# Logistic Regression Classifier Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Confusion Matrix : \\n\" + str(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdwAAAHwCAYAAAAMzd64AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAdG0lEQVR4nO3deZhldX3n8c+XbnYBaVbFBowiE8RoCMEluCWKaEiiiVFxiSTxcRnNZKITEx3HLZpJmGjUQRNNNAqKa9RoMKJjRFwyESSIgBuKAjayIwgIdPvLH+e0Fm11dXVR93e7r6/X89TTdc8595zfrVtd7zpL3VuttQAAk7XNtAcAAD8NBBcAOhBcAOhAcAGgA8EFgA4EFwA6EFy2SFW1Y1V9uKq+V1XvvR3reVJVfWw5xzYNVfUvVfXUaY9ja1dVx1XVZya4/ts8T1X1iqq6sqq+W1X7V9X3q2rFpLbPlk1wuV2q6olVdeb4g+TS8QfOkcuw6scm2SfJHq21317qSlpr72itHbUM47mNqnpIVbWqev8G0+89Tj9tket5aVW9fVPLtdYe2Vp72xKHu9D2DxzH+/3x47Kq+ueqevhyb6uXqnpEVZ1eVddX1RVV9amq+vUe2577PFXV6iTPS3JIa23f1tpFrbU7tNbW9RgLWx7BZcmq6rlJXpPkzzPEcf8kb0jyG8uw+gOSfK21tnYZ1jUpVyR5QFXtMWfaU5N8bbk2UIMe/0/v2Fq7Q5J7J/l4kg9U1XEdtrusquqxSd6b5MQkd8nwffniJL82heEckOSq1trlt3dFVbVyGcbDtLXWfPjY7I8kuyX5fpLfXmCZ7TMEec348Zok24/zHpLkkgx7AJcnuTTJ747zXpbkliS3jtv4/SQvTfL2Oes+MElLsnK8fVySbya5PsmFSZ40Z/pn5tzvAUnOSPK98d8HzJl3WpI/S/LZcT0fS7LnRh7b+vH/bZJnj9NWjNNenOS0Ocu+NsnFSa5L8oUkDxynH73B4/zinHG8chzHTUnuPk572jj/b5K8b876/zLJJ5LUEp7H23wd50z/H0kuS7LNeLslufuc+W9N8ooNvhbPn/NcPjrJozL88nF1khfOue9LM0Tx7ePX+UtJ7pHkBeP9L05y1Ljsbyf5wgZje16SD87zWCrJRUn+eIHHu+H3w7zPzTjviCRnjvMuS/LqcfoO49ivSnLt+H20z5zn7mlJHjY+dz8cn9u3bvi1zvB/6M3j1+s7SV6RZMWccX42yV+PX79XTPv/vI/b/2EPl6W6f4YfPB9YYJn/meR+Se6TYc/piCQvmjN/3ww/dPbLENXXV9XurbWXZNhrfncbDsG9eaGBVNXOSV6X5JGttV0yRPXseZZbleSUcdk9krw6ySkb7KE+McnvJtk7yXYZwrOQE5P8zvj5I5Kcl+GXi7nOyPA1WJXk5CTvraodWmsf3eBx3nvOfZ6S5OlJdkny7Q3W97wkPzeej3xghq/dU9v4k3qZvD/D1+DgRS6/b4bvh/0y/MLxd0menOQXkjwwyYur6mfmLP9rSU5KsnuS/0hyaoYjbvsleXmSN47LfSjJXavqZ+fc98njfTd0cJLVSd63yDEnG3luxnmvTfLa1tquSe6W5D3j9Kdm+L5dneH76JkZ4vojrbX/l+SRSdaMz+1x82z7bUnWZviF6ueTHJUh1uvdN8MvkXtn+AWMrZzgslR7JLmyLXzI90lJXt5au7y1dkWGPdenzJl/6zj/1tbaRzLsCSz2B/yGfpjk0KrasbV2aWvtvHmW+dUkX2+tndRaW9tae2eSr+S2hxv/obX2tdbaTRl+wN5noY221j6XZFVVHZwhvCfOs8zbW2tXjdt8VYY9/009zre21s4b73PrBuu7MUN0Xp1hT+sPWmuXbGJ9m2v9Lw2rFrn8rUleOY71XUn2zBCr68fn4rwkPzdn+U+31k4dv3/em2SvJH8x5/4HVtUdW2s3J3l3hsebqrpnhj3Ff55nDOt/cbp0kWPe1HNza5K7V9WerbXvt9b+/5zpe2TY41/XWvtCa+26xW5zfBz7ZAjyf2+t3dCGw85/neQJcxZb01r7v+PYbpp3RWxVBJeluirJnps4t3Tn3Hbv7NvjtB+tY4Ng35jkDps7kNbaDUken2FP49KqOqWq/ssixrN+TPvNuf3dJYznpCTPSfLQzLPHX1XPq6ovj1dcX5th72jPTazz4oVmttY+n2Hvp/LjPa+fUFXnzbkg6oGb2OZc678mVy9y+avajy8GWh+Hy+bMvym3/VpuOO/Kee6/fvm3JXliVVWGX9jeM4b4J8Yw/nunRY55U8/N72c41P2Vqjqjqo4Zp5+UYY/8XVW1pqqOr6ptF7vN0QFJts3w/XrtuO03ZtibXW/B7wG2PoLLUv1bkh9kOFe3MWsy/GBZb//85OHWxbohyU5zbu87d+a4t/TwDD9sv5LhkOamxrN+TN9Z4pjWOynJf03ykXHv80fGyP1Jkscl2b21dscM549r/dA3ss4FDw9X1bMz7I2tyXDudP6VtHbP8ZDmHVprn17Mgxk9JsP51K+Ot2/MAl//SRr3LG/JcGj6iZn/cHIyjPXiJL+1mPVu6rlprX29tXZshgj+ZZL3VdXO4xGZl7XWDslw+uKY/Pi0wmJdnOTmDNcI3HH82LW1ds85y3grtxkjuCxJa+17Gc7Vvb6qHl1VO1XVtlX1yKo6flzsnUleVFV7VdWe4/Kb/BOYjTg7yYPGv2XcLcMFNkmGw3NV9evjudybMxyanu9PLz6S5B7jnzKtrKrHJzkk8x+eXLTW2oVJHpzhnPWGdslwnu6KJCur6sVJdp0z/7IMh08X/X+xqu6R4QKbJ2fY43t+VS146Hsz1r1PVT0nyUuSvKC19sNx1tkZ9jJXVNXRGR5vTycmOSHJ2tbavH9HO57Dfm6S/1VVv1tVu1bVNlV1ZFW9aZ67LPjcVNWTq2qv8Wtw7Th5XVU9tKruNf497XUZDjFv1p/6tNYuzXBR3qvmjPNuVdX760pHgsuStdZeneEH3Isy/NC6OMOh1Q+Oi7wiw1We52S4EvWscdpStvXxDOfyzslwNencSG6T4UKiNRkOgT44wx7nhuu4KsPeyPMyHH58fpJjWmtXLmVMG6z7M621+fbeT03yLxmu1v12hqMCcw8Vrn9Rj6uq6qxNbWc8hP/2JH/ZWvtia+3rSV6Y5KSq2v52PIRrq+qGDM/TozJcff6WOfP/MMO57msznJv/4E+uYqJOSnJoNr53myRprb0vw+mF38vw/XBZhu+5f5pn8U09N0cnOa+qvp/hAqontNZ+kGHv/n0ZYvvlJJ/K0n6R/J0MF+adn+SacZ2LPhzO1qeW98JGgOVXVTtmOMR92PhLBmx17OECW4NnJTlDbNmaefUSYItWVd/KcCHTQhfowRbPIWUA6MAhZQDoQHABoIMt6hzunqtWtANXb+4LtgCL9bVzdtr0QsCS/SA35JZ2c803b4sK7oGrt83nT1097WHAzHrEnZfl9TGAjfj39omNznNIGQA6EFwA6EBwAaADwQWADgQXADoQXADoQHABoAPBBYAOBBcAOhBcAOhAcAGgA8EFgA4EFwA6EFwA6EBwAaADwQWADgQXADoQXADoQHABoAPBBYAOBBcAOhBcAOhAcAGgA8EFgA4EFwA6EFwA6EBwAaADwQWADgQXADoQXADoQHABoAPBBYAOBBcAOhBcAOhAcAGgA8EFgA4EFwA6EFwA6EBwAaADwQWADgQXADoQXADoQHABoAPBBYAOBBcAOhBcAOhAcAGgA8EFgA4EFwA6EFwA6EBwAaADwQWADgQXADoQXADoQHABoAPBBYAOBBcAOhBcAOhAcAGgA8EFgA4EFwA6EFwA6EBwAaADwQWADgQXADoQXADoQHABoAPBBYAOBBcAOhBcAOhAcAGgA8EFgA4EFwA6EFwA6EBwAaADwQWADgQXADoQXADoQHABoAPBBYAOBBcAOhBcAOhAcAGgA8EFgA4EFwA6EFwA6EBwAaADwQWADgQXADoQXADoQHABoAPBBYAOBBcAOhBcAOhAcAGgA8EFgA4EFwA6EFwA6EBwAaADwQWADgQXADoQXADoYOW0B8CWq/7osuTjNyZ7rkg7bf9h4jXrUs/8bnLx2mT1yrQ37pvccUXyqRtTr7wqubUl21bai/dIjtxpug8AtmLPa2fmvrk012b7PL2OmvZwWAYT3cOtqqOr6qtVdUFV/ekkt8Xya4/bNe3kO91mWp1wTdqRO6V97oC0I3dKnXDNMGPVirQT75T2yf3TXrd36g8um8KIYXZ8LAfkhTly2sNgGU0suFW1IsnrkzwyySFJjq2qQya1PSbg/jsmu6+47bRTb0get8vw+eN2ST56w/D5vbZP9h0PmBy8XXJzGz6AJflS7ZXrs920h8EymuQe7hFJLmitfbO1dkuSdyX5jQlujx6uWJfsM4Z1n5XJlet+cplTbkgO3T7ZvvqODWALNsng7pfk4jm3LxmnMcu+enPqFVemHb/3tEcCsEWZZHDn2735iWOMVfX0qjqzqs684qp59pbYsuy1Irls7fD5ZWuTPecccl6zNvV730173T7JgdtOZ3wAW6hJBveSJKvn3L5LkjUbLtRae1Nr7fDW2uF77bFiw9lsaY7aOXnP9cPn77k+ecTOw+ffW5d6ypq0F+yRHLHj9MYHsIWaZHDPSHJQVd21qrZL8oQkH5rg9lhm9azvpo65JPnGLanDLkxOvi7tObunTr8x9YBvp06/Me05uw8Lv+V7yYW3pl5zdephF6UedlFy5drpPgDYir2w/Xtem09mda7Pye2UHN0unPaQuJ2qtcldSVpVj0rymiQrkryltfbKhZY//N47tM+funqhRYDb4RF3vs+0hwAz7d/bJ3Jdu3reK0Yn+sIXrbWPJPnIJLcBAFsDL+0IAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQgeACQAeCCwAdCC4AdCC4ANCB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQgeACQAeCCwAdCC4AdCC4ANCB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQgeACQAeCCwAdCC4AdCC4ANCB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQgeACQAeCCwAdCC4AdCC4ANCB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQgeACQAeCCwAdCC4AdCC4ANCB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQgeACQAeCCwAdCC4AdCC4ANCB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQwcqNzaiqwxa6Y2vtrOUfDgDMpo0GN8mrFpjXkvzyMo8FAGbWRoPbWntoz4EAwCzb5Dncqtqpql5UVW8abx9UVcdMfmgAMDsWc9HUPyS5JckDxtuXJHnFxEYEADNoMcG9W2vt+CS3Jklr7aYkNdFRAcCMWUxwb6mqHTNcKJWquluSmyc6KgCYMQtdpbzeS5J8NMnqqnpHkl9KctwkBwUAs2aTwW2tfbyqzkpyvwyHkv+wtXblxEcGADNkMXu4SfLgJEdmOKy8bZIPTGxEADCDFvNnQW9I8swkX0pybpJnVNXrJz0wAJgli9nDfXCSQ1tr6y+aeluG+AIAi7SYq5S/mmT/ObdXJzlnMsMBgNm00JsXfDjDOdvdkny5qj4/3r5vks/1GR4AzIaFDin/VbdRAMCMW+jNCz7VcyAAMMsWc5Xy/arqjKr6flXdUlXrquq6HoMDgFmxmIumTkhybJKvJ9kxydPGaQDAIi3qhS9aaxdU1YrW2rok/1BVLpoCgM2wmODeWFXbJTm7qo5PcmmSnSc7LACYLYs5pPyUcbnnJLkhw9/h/uYkBwUAs2Yxb17w7fHTHyR5WZJU1buTPH6C4wKAmbKYPdz53H9ZRwEAM26pwQUANsNCL+142MZmZXiLvmX39fN3zaPu/fBJrBpI8o2T95v2EGCm3fzCjf8Rz0LncF+1wLyvLHk0APBTaKGXdnxoz4EAwCxzDhcAOhBcAOhAcAGgg8W8W1BV1ZOr6sXj7f2r6ojJDw0AZsdi9nDfkOGFLo4db1+f5PUTGxEAzKDFvHnBfVtrh1XVfyRJa+2a8c0MAIBFWswe7q1VtSJJS5Kq2ivJDyc6KgCYMYsJ7uuSfCDJ3lX1yiSfSfLnEx0VAMyYxbxb0Duq6gtJfiXDyzo+urX25YmPDABmyCaDW1X7J7kxyYfnTmutXTTJgQHALFnMRVOnZDh/W0l2SHLXJF9Ncs8JjgsAZspiDinfa+7t8V2EnjGxEQHADNrsV5pqrZ2V5BcnMBYAmFmLOYf73Dk3t0lyWJIrJjYiAJhBizmHu8ucz9dmOKf7j5MZDgDMpgWDO77gxR1aa3/caTwAMJM2eg63qla21tZlOIQMANwOC+3hfj5DbM+uqg8leW+SG9bPbK29f8JjA4CZsZhzuKuSXJXkl/Pjv8dtSQQXABZpoeDuPV6hfG5+HNr12kRHBQAzZqHgrkhyh9w2tOsJLgBshoWCe2lr7eXdRgIAM2yhV5qab88WAFiChYL7K91GAQAzbqPBba1d3XMgADDLNvvNCwCAzSe4ANCB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQgeACQAeCCwAdCC4AdCC4ANCB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQgeACQAeCCwAdCC4AdCC4ANCB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQgeACQAeCCwAdCC4AdCC4ANCB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQgeACQAeCCwAdCC4AdCC4ANCB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQgeACQAeCCwAdCC4AdCC4ANCB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQgeACQAeCCwAdCC4AdCC4ANCB4AJAB4ILAB2snPYA2PrcZe01ecF1H//R7X3XXZeTdv7FfHCne09xVLD12+WGm/IXb/pg7nHJZWmp/MkzHpN9r74uf/i+f83d11yRx/zZM/Olu+037WGyRBMLblW9JckxSS5vrR06qe3Q3yUrd8+zVz0uSbJN+2HeftWJ+dz2PzPlUcHW78VvOyWfuvdBefYfHZtt167NDjffmut23iHPeu6xeeXf/9O0h8ftNMlDym9NcvQE188W4D63fCeXrtgtl6/YZdpDga3aHW78QY74yrfynof+QpLk1pUrc/3OO+Yb++2dC++815RHx3KY2B5ua+30qjpwUutny/Dgmy/IadvffdrDgK3e6suvydW77pzj//b9+dlvfzfn/syd8/Lf+dXctMN20x4ay8RFUyzZyrYu97v5W/n0Dneb9lBgq7dy3Q9zzwsvzTsefkR+7S+enRu33y7P/NDp0x4Wy2jqwa2qp1fVmVV15i0/vGnaw2EzHH7LRblg5Z65dpudpj0U2Opduseu+e6qXfPFu69Oknz0vvfMoReumfKoWE5TD25r7U2ttcNba4dvt82O0x4Om+EhP7ggp+1w0LSHATPhyjvukkv32C13XXNFkuQB534jX7/L3lMeFcvJnwWxJNu3W3PYLRfndbs8aNpDgZnx0uOOyWtOeG+2XbsuF+2zKs9/xm/mqDPOz0ve+s9Zdd0NefPxJ+b8A++U415w3LSHyhJUa20yK656Z5KHJNkzyWVJXtJae/NC99lt273b/Vc9diLjAZKvvdbfcMIkfeeFb8jN3/xOzTdvklcpHzupdQPA1mbq53AB4KeB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQgeACQAeCCwAdCC4AdCC4ANCB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQgeACQAeCCwAdCC4AdCC4ANCB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQgeACQAeCCwAdCC4AdCC4ANCB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQgeACQAeCCwAdCC4AdCC4ANCB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQgeACQAeCCwAdCC4AdCC4ANCB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQgeACQAeCCwAdCC4AdCC4ANCB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQgeACQAeCCwAdCC4AdCC4ANCB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHQguADQgeACQAeCCwAdCC4AdCC4ANCB4AJAB4ILAB0ILgB0ILgA0IHgAkAHggsAHQguAHRQrbVpj+FHquqKJN+e9jhYtD2TXDntQcCM8/9s63JAa22v+WZsUcFl61JVZ7bWDp/2OGCW+X82OxxSBoAOBBcAOhBcbo83TXsA8FPA/7MZ4RwuAHRgDxcAOhBclqSqjq6qr1bVBVX1p9MeD8yaqnpLVV1eVedOeywsD8Fls1XViiSvT/LIJIckObaqDpnuqGDmvDXJ0dMeBMtHcFmKI5Jc0Fr7ZmvtliTvSvIbUx4TzJTW2ulJrp72OFg+gstS7Jfk4jm3LxmnAbARgstS1DzTXO4OsADBZSkuSbJ6zu27JFkzpbEAbBUEl6U4I8lBVXXXqtouyROSfGjKYwLYogkum621tjbJc5KcmuTLSd7TWjtvuqOC2VJV70zyb0kOrqpLqur3pz0mbh+vNAUAHdjDBYAOBBcAOhBcAOhAcAGgA8EFgA4EFyakqtZV1dlVdW5Vvbeqdrod63prVT12/PzvF3qziKp6SFU9YAnb+FZV7bnY6RtZx3FVdcJybBdmjeDC5NzUWrtPa+3QJLckeebcmeO7Lm221trTWmvnL7DIQ5JsdnCByRJc6OPTSe4+7n1+sqpOTvKlqlpRVf+nqs6oqnOq6hlJUoMTqur8qjolyd7rV1RVp1XV4ePnR1fVWVX1xar6RFUdmCHsfzTuXT+wqvaqqn8ct3FGVf3SeN89qupjVfUfVfXGzP8a2fOqqiOq6nPjfT9XVQfPmb26qj46vl/yS+bc58lV9flxXG9c6i8csLVaOe0BwKyrqpUZ3jv4o+OkI5Ic2lq7sKqenuR7rbVfrKrtk3y2qj6W5OeTHJzkXkn2SXJ+krdssN69kvxdkgeN61rVWru6qv42yfdba381Lndykr9urX2mqvbP8AphP5vkJUk+01p7eVX9apKnb8bD+sq43bVV9bAkf57kt+Y+viQ3Jjlj/IXhhiSPT/JLrbVbq+oNSZ6U5MTN2CZs1QQXJmfHqjp7/PzTSd6c4VDv51trF47Tj0ryc+vPzybZLclBSR6U5J2ttXVJ1lTVv86z/vslOX39ulprG3vv1IclOaTqRzuwu1bVLuM2fnO87ylVdc1mPLbdkrytqg7K8E5R286Z9/HW2lVJUlXvT3JkkrVJfiFDgJNkxySXb8b2YKsnuDA5N7XW7jN3whibG+ZOSvIHrbVTN1juUdn0Wx7WIpZJhlNH92+t3TTPWJb62q5/luSTrbXHjIexT5szb8N1tnGsb2utvWCJ24OtnnO4MF2nJnlWVW2bJFV1j6raOcnpSZ4wnuO9U5KHznPff0vy4Kq663jfVeP065PsMme5j2V4s4mMy63/JeD0DId1U1WPTLL7Zox7tyTfGT8/boN5D6+qVVW1Y5JHJ/lskk8keWxV7b1+rFV1wGZsD7Z6ggvT9fcZzs+eVVXnJnljhiNPH0jy9SRfSvI3ST614R1ba1dkOO/6/qr6YpJ3j7M+nOQx6y+aSvLfkhw+XpR1fn58tfTLkjyoqs7KcGj7ogXGec74jjWXVNWrkxyf5H9X1WeTbHjx02eSnJTk7CT/2Fo7c7yq+kVJPlZV5yT5eJI7LfJrBDPBuwUBQAf2cAGgA8EFgA4EFwA6EFwA6EBwAaADwQWADgQXADoQXADo4D8BA40+4m9c3ykAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=(\"0\", \"1\"))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=(\"0\", \"1\"))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"red\")\n",
    "plt.title(\"Confusion Matrix - Dummy Classifier\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1302, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1302, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1302, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1302, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1302, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1302, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1302, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1302, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.9415204678362573\n",
      "Precision Score : 0.9833333333333333\n",
      "Recall Score : 0.8676470588235294\n",
      "F1 Score : 0.9218749999999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[102,   1],\n",
       "       [  9,  59]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = LogisticRegression()\n",
    "grid_values = {\"penalty\": [\"l1\", \"l2\"], \"C\": [0.001, 0.009, 0.01, 0.09, 1, 5, 10, 25]}\n",
    "grid_clf_acc = GridSearchCV(clf, param_grid=grid_values, scoring=\"recall\")\n",
    "grid_clf_acc.fit(X_train, y_train)\n",
    "\n",
    "# Predict values based on new parameters\n",
    "y_pred_acc = grid_clf_acc.predict(X_test)\n",
    "\n",
    "# New Model Evaluation metrics\n",
    "print(\"Accuracy Score : \" + str(accuracy_score(y_test, y_pred_acc)))\n",
    "print(\"Precision Score : \" + str(precision_score(y_test, y_pred_acc)))\n",
    "print(\"Recall Score : \" + str(recall_score(y_test, y_pred_acc)))\n",
    "print(\"F1 Score : \" + str(f1_score(y_test, y_pred_acc)))\n",
    "\n",
    "# Logistic Regression (Grid Search) Confusion matrix\n",
    "confusion_matrix(y_test, y_pred_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=(\"0\", \"1\"))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=(\"0\", \"1\"))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"red\")\n",
    "plt.title(\"Confusion Matrix - Dummy Classifier\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f946df053fbf2b937619d3c5458e7af74262f9a954d8797ba0b27400bcafe06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
