{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 12:28:21.744530: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 12:28:25.052229: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-23 12:28:25.052278: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-23 12:28:25.396317: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-23 12:28:32.088966: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-23 12:28:32.089253: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-23 12:28:32.089269: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "path = keras.utils.get_file(\n",
    "    \"nietzsche.txt\", origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\"\n",
    ")\n",
    "text = open(path).read().lower()\n",
    "print(\"Corpus length:\", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 200278\n",
      "Unique characters: 57\n",
      "Vectorization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14664/2567106722.py:26: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
      "/tmp/ipykernel_14664/2567106722.py:27: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "# Length of extracted character sequences\n",
    "maxlen = 60\n",
    "\n",
    "# We sample a new sequence every `step` characters\n",
    "step = 3\n",
    "\n",
    "# This holds our extracted sequences\n",
    "sentences = []\n",
    "\n",
    "# This holds the targets (the follow-up characters)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i : i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print(\"Number of sequences:\", len(sentences))\n",
    "\n",
    "# List of unique characters in the corpus\n",
    "chars = sorted(list(set(text)))\n",
    "print(\"Unique characters:\", len(chars))\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# Next, one-hot encode the characters into binary arrays.\n",
    "print(\"Vectorization...\")\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 12:28:42.420954: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-23 12:28:42.421002: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-23 12:28:42.421036: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (codespaces-f22901): /proc/driver/nvidia/version does not exist\n",
      "2022-10-23 12:28:42.439265: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the language model and sampling from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 12:28:43.534587: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 684950760 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1565/1565 [==============================] - 156s 97ms/step - loss: 1.9690\n",
      "--- Generating with seed: \"transition from religion by way of science entails a powerfu\"\n",
      "------ temperature: 0.2\n",
      "transition from religion by way of science entails a powerful of the conscience of the consequently the consequently and general and the consequently and sense of the consequently and the consequently the sense of the conseral and the consertion of the consertion of the sense of the consertion of the consequently and the sense of the consequently and the former the conserder the conseral and the consertion of the consequently sense of the consequently some\n",
      "------ temperature: 0.5\n",
      "onsertion of the consequently sense of the consequently some the philosophice the sense and enthere of the for the conscience of the sense and conserre and we disting and very have for the fair for the intere it it has former, and the netefound, this is the can conserration and though of and the condition of and the that the and say the self-all the some he all consequent of the parth of all say consequent in think perpainish without man, and perpain of an\n",
      "------ temperature: 1.0\n",
      "onsequent in think perpainish without man, and perpain of ant de, delumanes.\n",
      "\n",
      "\n",
      "23 geolncisus.\n",
      "\n",
      "1ju led could ictull conscientables it \"myy seest.\n",
      "oncesivelusl, ame caming strain with his is this\n",
      "a this,--in\n",
      "inceariwic at erride leagh of the waonly ejesply which is pogfater of nature and lowenous\n",
      "and serition of the and one ony, the lobed\n",
      "upops it stood-cear. uninest. you not wey\n",
      "is care the \"goodunalual yeitht and most disidnesticestam of ascise and buts.\n",
      "\n",
      "------ temperature: 1.2\n",
      "nalual yeitht and most disidnesticestam of ascise and buts.\n",
      "\n",
      ": hhaugh\n",
      "there kildolonle furds and breses infuling it impate, givelye.\n",
      "  due:\n",
      "\"the men commardschict, ; artwele for the \"hatteges--so lon eall. themethan betagial your vermpos. (sived empisroods of\n",
      "the lugnest.--this oncoltary your fold hig  caulfy-to thesernes corsupt contervaen pesmpel) ose hil\n",
      "antaic\n",
      "and myhe. the long, distraed and taychirn op chare; that fign course oevive it eartewhe tise \n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 12:33:02.600670: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 684950760 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1565/1565 [==============================] - 148s 94ms/step - loss: 1.6141\n",
      "--- Generating with seed: \"this sentiment be\n",
      "left to men of the masses who stand in nee\"\n",
      "------ temperature: 0.2\n",
      "this sentiment be\n",
      "left to men of the masses who stand in needs all the self-course of the self-castions of the self-conscience of the self-consequently instincts, and the self-case of the self-consequently and stronger and delight and stronger and all the self-course of the self-conscience, and the sense of the same are all the stronger and more instinct of the self-coural and some to self-creater and all the self-conscience of the self-course of the self-\n",
      "------ temperature: 0.5\n",
      " and all the self-conscience of the self-course of the self-case of the believes have been seems to all been does the self-concerning the fulless for the stronger of his instinct for the more every sentimentally of the self-nothing the will to seems of philosophy, which has no more but an etrary latter and self inasmisching in the men of the accordances of the\n",
      "foredly and worth for morality in the sacrifice. the will so stronger, one case in the man and a \n",
      "------ temperature: 1.0\n",
      " sacrifice. the will so stronger, one case in the man and a compariin this must prourualick\n",
      "discormucal pravess prosonour, a venselly, and love as rarm, belure nawure,\" and tercharl\n",
      "to\n",
      "seems complession, alweady mains has destious interrestion, but an a virtueser--farisent heredound in the gridute respons and case of which inverlually many-- this make religious tay its reasons, one has convinced intererialty, utpisit\", \n",
      "contineally german consequentle of t\n",
      "------ temperature: 1.2\n",
      "ntererialty, utpisit\", \n",
      "contineally german consequentle of thinkouncenis\". a discovally one's decrohougness, its long in \"tater\n",
      "omer nothorpus becapsently re from true by the some! the germanif,;\n",
      "spiritmss merelingly rated their\n",
      "sake.--ersolate astints in rank, all of thrse does notrisey betray, every of wlice freelife counses\n",
      "houst-itself the unsclultictarl\n",
      "believery, mare has presticl impliegeting fole\" elack from moreing there decordite, variency\n",
      "-manwa\n",
      "epoch 3\n",
      "   1/1565 [..............................] - ETA: 2:35 - loss: 1.3690"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 12:37:01.386661: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 684950760 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 516/1565 [========>.....................] - ETA: 1:44 - loss: 1.5210"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 60):\n",
    "    print(\"epoch\", epoch)\n",
    "    # Fit the model for 1 epoch on the available training data\n",
    "    model.fit(x, y, batch_size=128, epochs=1)\n",
    "\n",
    "    # Select a text seed at random\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index : start_index + maxlen]\n",
    "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print(\"------ temperature:\", temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        # We generate 400 characters\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.0\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
